{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b75b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# PDF 가져오기\n",
    "loaders = [\n",
    "    PyPDFLoader(r\".\\거대 언어 모델의 한국 이해도.pdf\"),\n",
    "    PyPDFLoader(r\".\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04536bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<langchain_community.document_loaders.pdf.PyPDFLoader at 0x1c73b70d4d0>,\n",
       " <langchain_community.document_loaders.pdf.PyPDFLoader at 0x1c73b39bad0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc444a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='1. 서 론\\n대규모 언어모델((Large Language Model, 이하\\nLLM)은 지난 5년 동안 꾸준한 성장을 보였지만,\\nOpenAI사에서 개발한 ChatGPT 서비스의 등장 이후\\n세계적으로 LLM의 활용 방안에 관한 다양한 시도가\\n이어지고 있다. LLM은 자연어를 이해하고 또한\\n생성할 수 있도록 만들어진 대규모 딥러닝 모델이며,\\n이를 개발하기 위해서 대규모 학습데이터와 모델링\\n작업이 수행되어야 한다. 따라서 데이터와 자본의\\n한계로 해외 유명 IT 기업을 중심으로 발전하고 있어\\n국내 IT 기업의 노력에도 충분한 한국어 능력을\\n기반한 서비스 제공에 한계가 있을 수 있다는 걱정도\\n존재한다.\\n이에 본 연구에서는 한국어를 학습한 LLM 모델\\n들을 중심으로 한국어 이해 능력을 평가하기 위해\\nKBS 한국어 능력 시험・TOPIK 등 한국어와 관련된\\n시험 문제를 중심으로 데이터셋을 구성하고 LLM의\\n성능 평가를 진행하였다. 이는 LLM의 한국어 이해\\n및 활용 능력을 객관적으로 평가하고 서비스 제공을\\n위한 가장 적절한 LLM의 선정 시 기본적인 정보를\\n제공할 수 있다.\\n2. 관련 연구\\n2.1 LLM 개념\\nLLM은 대규모의 언어모델을 의미하며, 거대한\\n데이터셋을 사용하여 훈련된 언어모델을 의미한다.\\n사전에 대규모의 언어 데이터를 학습하여 문장 구조,\\n문법, 의미, 단어 내에 내재된 다른 의미를 이해하고\\n이를 활용해 사람이 말하는 것과 유사하게 자연어를\\n생성할 수 있다. 최근 국내 주요 기업들도 초거대\\n인공지능 시스템 구축에 주력하고 있으며 이러한\\nLLM의 필요성은 더욱 커지고 있다[1][2].\\n2.2 트랜스포머(Transformer) 모델\\n2017년 트랜스포머 아키텍처의 등장과 함께 거대\\n대규모 언어모델의\\n한국어 이해 능력 평가 방법에 관한 연구\\n손기준1, 김승현2\\n1오피니언라이브 AI데이터센터장\\n2한국지능정보사회진흥원 책임연구원\\nkijunson@opinionlive.co.kr, shkim@nia.or.kr\\nA Study on the Evaluation Method of Korean\\nComprehension Abilities of Large Language Model\\nKi Jun Son1, Seung Hyun Kim2\\n1Dept. of AI Data, Opinionlive\\n2Dept. of AI Data, National Information society Agency\\n요 약\\n최근 GTP4, LLama와 같은 초거대 언어모델을 활용한 서비스가 공개되어 많은 사람의 주목을 받고\\n있다. 해당모델들은사용자들의다양한질문에대하여유창한결과를생성하고있지만한국어데이터에\\n대한 학습량이 부족하여 한국어 이해 및 한국 문화 등에 대한 잘못된 정보를 제공하는 문제를\\n야기할수있다. 이에본논문에서는한국어데이터를학습한주요공개모델6개를선정하고5개분야\\n(한국어 이해 및 문화 영역으로 구성)에 대한 평가 데이터셋을 구성하여 한국어 이해 능력에 대한\\n평가를 진행하였다. 그 결과 한국어 구사 능력은 Bookworm 모델이, 한국어 이해 및 문화와 관련한\\n부문은 LDCC-SOLAR 모델이 우수한 것으로 확인할 수 있었다.\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x003\\x00 \\x00-'),\n",
       " Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='언어모델이등장하기시작하였으며트랜스포머모델의\\n아키텍처는 RNN, CNN을 사용하지 않고 Positional\\nEncoding을 사용하며 다수의 인코더(Encoder)와\\n디코더(Decoder)와 Attention 메커니즘을 사용한다.\\nPostional Encoding을사용하며Attention 과정을여러\\n레이어에서 반복수행하면서문장 내문맥 간의상호\\n작용에 대한 정교한 모델링이 가능하게 되었다. 이를\\n통해 번역이나 요약과 같은 작업에서 Attention과\\nNomalization 작업을 통해 성능향상을 가져왔으며\\n가장 중요한 정보를강조하여 분석할 수 있게 되었\\n다[3].\\nGoogle은 2018년 BERT (Bidirectional Encoder\\nRepresentation from Transformers)를 공개하였다.\\nBERT는 트랜스포머 모델의 인코더 아키텍처를\\n기반으로 양방향 해석을 통해 텍스트를표현하는\\n학습모델이다[4]. LLM은 대부분 트랜스포머 아키텍처\\n에서 파생된 AI 모델로, 사람의 언어, 코드 등을\\n이해하고 생성할 수 있게 되었다.\\n3. LLM 모델 평가\\n3.1 평가 모델 및 항목 선정\\n최신 기술의 발전과 더불어 다양한 LLM이 공개\\n및 개방되고 있으며 이에 사용자가 모델들의 성능을\\n객관적이고세부적으로 판단할수있도록다양한평가\\n방안이 제시되고 있다. 가장 대중적으로 알려진\\nHugging Face Open LLM Leaderboard는<표1>과\\n같이 총 6가지 분야에 대한 성능을 평가하여순위를\\n정하고 있다.\\n<표1>HuggingFace Open LLM Leaderboard 평가항목\\n항목 내용\\n1 ARC 초등수준의 과학문제\\n2 HellaSwag 특정 상황에서의 언어 추론 능력 평가\\n3 MMLU 사전학습 된 모델의 지식을 평가\\n4 TruthfulQA 환각현상 방지 능력\\n5 Winogrande 상식적 추론을 평가\\n6 GSM8k 다단계 수학적 추론 평가\\n또한 한국어 모델을 위하여 NIA-업스테이지에서\\n운영하는OpenKo-LLM 리더보드가운영되고있으며\\n역사왜곡,환각오류,형태소오류,불규칙활용오류,\\n혐오 표현 등을 고려한 상식생성 기준을바탕으로\\n한국어사용자가가지고있는 일반상식에부합하는지를\\n기준으로 모델의 성능을 평가하고 있다.\\n먼저 평가 모델을 선정하기 위하여 2024년 2월을\\n기준으로 HuggingFace Leaderboard의 상위 100위\\n모델이며 Open Ko-LLM리더보드의 상위30위에\\n중복으로 포함된 모델을 우선 선정하였다. 그 후\\n공공부문에서활용성을고려하여한국어가학습된공개\\n모델이며, 평가에 활용할 수 있는 인프라의 성능을\\n고려하여 모델 사이즈가 12.8B 이하인 모델을 기준\\n으로 검토하여 최종적으로 <표2>에서 제시한 6개의\\n평가 모델을 선정하였다.\\n<표2>평가에활용할LLM모델\\n모델명\\n1 LDCC-SOLAR-10.7B[6]\\n2 Bookworm-10.7B[7]\\n3 SOLARC-M-10.7B[8]\\n4 Llama-2-13b-chat-hf[9]\\n5 Kullm-solar[10]\\n6 KoAlpaca-Polyglot-12.8B[11]\\n*모든모델은2024년 3월20일자모델을다 운로드함\\nSOLAR모델은AI스 타트업인업스테이지에서자체\\n개발한LLM모델이며Hugging FaceLeaderboard에서\\n1위에오른적이있는모델이다. LDCC-SOLAR모델의\\n경우롯데정보통신에서SOLAR모델을 바탕으로자체\\n구축데이터를 추가 학습하여 만들어진 모델이며,\\nSOLARC-M모델의 경우SOLAR-Instruction 모델에\\nMerge기술을이용하여모델을최적화한모델이다.\\nKullm-solar 모델은 SOLAR-Instruction 모델에\\n고려대학교에서 만든 구름 데이터셋을 학습한 모델로\\nOpenKo-LLM 리더보드에서15위에기록된적이있다.\\nBookworm은야놀자에서업스테이지의SOLAR모델을\\n베이스로 자체 제작한 데이터셋을 학습한 후 미세\\n조정한모델이다.\\n3.2 평가 데이터셋 구성 및 방법\\n앞서설명한Hugging FaceOpenLLMLeaderboard\\n에서 선정한 6가지 분야의 성능 지표를 바탕으로\\n공공부문과 민간부문의 한국어 사용성을 고려하여\\n한국어 능력, 한국사, 한국지리, 문학, 문법 등을\\n폭넓게 평가할 수 있는 문제로총 5가지 분야 431개\\n문항을 만들어 평가를 진행하였다.\\n<표3>최종선정된평가분야\\n데이터명(문항) 내용\\n1 KBS 한국어 능력시험(88) 한국어 문장 구조 평가\\n2 TOPIK(203) 외국인 대상 한국어 평가\\n3 한국사 능력 검정시험(40) 한국의 역사 문화 평가\\n4 국내여행안내사(50) 한국 지리적 특성 평가\\n5 공무원 9급시험(50) 문학, 문법 등 한국어 평가\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x004\\x00 \\x00-'),\n",
       " Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='<표4>LLM 성능 평가 데이터셋 구성예시\\n데이터셋 Question Answer 유형 분류\\nKBS 한국어 능력 시험\\nQ : 〈보 기〉에 제시된 단어의 발음이 표준 발음인 것끼리 묶인 것은?\\nE : <보 기> ㄱ)의심[의심]  ㄴ)본의[본이] ㄷ)닁큼[닝큼] ㄹ)무늬[무늬]\\nO : 1. ㄱ,ㄴ 2.ㄱ,ㄷ 3. ㄴ,ㄷ 4. ㄴ,ㄹ 5. ㄷ,ㄹ\\n2 (단일)정답형 어법\\nTOPIK\\nQ : ( )에 들어갈 말로 가장알맞은 것을 고르십시오.\\n    다른 사람과 대화를 할 때는 적당한 거리를(  ) 한다. \\nO : 1. 유지해야 2. 유지하는 3. 유지했고 4. 유지하니까\\n1 불완전\\n문장형 읽기\\n한국사 능력 검정시험\\nQ : (가)에 해당하는 인물로 옳은 것은?\\nE : 이곳 경복궁은 조선의 궁궐로 (가)이/가 이름 지었대. 국왕과 백성이 만년토\\n록 태평하며 큰 복을 누리기를 바란다는 의미가 담겨 있어. 그는 새 왕조의 통\\n치 방향을 제시한 조선경국전도 저술하였지.\\nO : 1.송시열 2.채제공 3.정몽주 4.정도전\\n4 (단일)정답형 기본\\n국내여행안내서\\nQ : 소재지와 동굴의 연결이 옳은 것은?\\nO : 1. 경북 안동 - 성류굴\\n    2. 강원 삼척 - 고씨굴\\n    3. 전북 익산 - 천호동굴\\n    4. 충북 단양 - 초당굴\\n3 짝짓기형 관광자원\\n해설\\n공무원 9급시험\\nQ: 관용표현 ㄱ∼ㄹ의 의미를 풀이한 것으로 적절하지 않은 것은?\\n  - 그의 회사는 작년에 노사 갈등으로 ㄱ홍역을 치렀다. \\n  - 우리 교장 선생님은 교육계에서 ㄴ잔뼈가 굵은 분이 십니다.\\n  - 유원지로 이어지는 국도에는 차가 밀려 ㄷ입추의 여지가 없었다.\\n  - 그분은 세계 유수의 연구자들과 ㄹ어깨를 나란히 하는 물리학자이다.\\nO : 1. ㄱ: 심한 어려움을 겪었다 2. ㄴ:오랫동안 일을 하여 그 일에 익숙한 \\n    3. ㄷ: 돌아서 갈 수 있는 방법이 없었다 4. ㄹ:비슷한 지위나 힘을 가지는\\n3\\n불완전 \\n문장형 어휘\\n<표5>LLM 평가 결과\\n모델명\\nKBS 한국어 능력시험 TOPIK 한국사능력검정시험 국내여행안내사 공무원 9급 시험\\n정답수 비율(%) 정답수 비율(%) 정답수 비율(%) 정답수 비율(%) 정답수 비율(%)\\nLDCC-SOLAR-10.7B 20 23 146 72 18 45 23 46 28 55\\nBookworm-10.7B 21 24 152 75 10 25 21 42 26 51\\nSOLARC-M-10.7B 15 17 141 70 14 35 20 4 23 45\\nLlama-2-13b-chat-hf 18 20 83 41 0 0 9 18 11 22\\nKullm-solar 8 9 87 43 2 5 6 12 10 20\\nKoAlpaca-Polyglot-12.8B 13 15 33 16 8 2 12 24 6 12\\n3.3 평가 결과\\n선정된 LLM의 한국어 이해에 대한 평가를 진행\\n하기 위하여 평가에 활용할 데이터셋<표4>을 객관식\\n문제 유형으로 구성하였다. 평가는 모델별 입력구조가\\n다양하여 입력 형식에 맞추어 프롬프트를 구성한 후\\n테스트를 진행하였다.\\n한국어 능력을 평가하기 위해서 시행한‘KBS\\n한국어 능력 시험’과‘TOPIK’ 시험의 결과는<표5>와\\n같다.‘KBS 한국어 능력 시험’의경우 문법과 어휘를\\n중심으로 한국어 문장의 구조를 이해하는 능력을\\n평가하게 되며,‘TOPIK’의 경우 한국어를 모국어로\\n사용하지 않는 이를 대상으로 수행되는 시험으로\\n언어의 사용 및 이해도에 대한 평가로 Bookworm\\n모델이 가장높은 정답률을 보였다.\\n‘한국사능력검정시험’과 ‘국내 여행 안내사 시험’의\\n경우는 한국의 역사와 문화 지식 측정이 목표인 시험\\n으로LDCC-SOLAR모델이가장 좋은성능을보였다.\\n‘공무원 9급 시험’의 경우 한국 문학, 문법, 한자\\n표현 등을 포함한 한국어 능력을폭넓게 평가하여\\n문장의 맥락을 정확히이해하고 사용할 수 있는지\\n평가하게 된다.‘국내 여행 안내사 시험’과‘공무원9급\\n시험’의 경우 LDCC_SOLAR 모델의 정답률이 가장\\n높게 나왔으며 Boookworm 모델이 근소한차이로\\n두번째로좋은정답률을보이는것을확인할수있다.\\n모델별 평가 결과는<표6>에서 확인할 수 있다.\\n롯데정보통신의 LDCC-SOLAR가 가장좋은 결과를\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x005\\x00 \\x00-'),\n",
       " Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='나타냈으며, 야놀자의 Bookworm이 2순위를 기록하였\\n으며 SOLARC-M 모델도 정답률이 49%로 준수한\\n결과를 보여주었다. 다만 나머지3개 모델은 정답률이\\n30%에 미치지 못하여 상대적으로낮은 수준을 나타\\n냈음을확인할수있다.\\n<표6>LLM 평가 결과종합\\n순위 모델명 정답수 비율(%)\\n1 LDCC-SOLAR-10.7B 235 55\\n2 Bookworm-10.7B 230 53\\n3 SOLARC-M-10.7B 213 49\\n4 Llama-2-13b-chat-hf 121 28\\n5 Kullm-solar 113 26\\n6 KoAlpaca-Polyglot-12.8B 72 17\\n상위권을기록한모델들의공통 점은베이스모델을\\n모두업스테이지가개발한SOLAR를기본으로만들어\\n졌음을 확인할 수 있다. SOLAR 모델의경우 LLM의\\n효율적인확장을위한 깊이기반스 케일링과지속적인\\n사전 훈련을 통해 모델을 구축하였으며,롯데정보\\n통신과 야놀자에서는 자체 구축데이터를 통해서\\n한국어와 관련한 다양한 분야의추가 학습이 지속해서\\n진행되어 높은 정답률을 보일수 있던 것으로 판단\\n된다. 따라서우수한데이터를지속해서학습하는것이\\nLLM의 성능을높일 수 있는 가장좋은 방법임을\\n확인할 수 있다.\\n4. 결 론\\n공공분야 및 민간분야에서의 LLM을 활용하여\\n다양한 서비스 제공을 위해 노력하고 있다. 이를 위\\n해선 서비스의 목적에맞는 모델을 선정하고 해당\\n모델의 장단점을 정확히 이해하는 것에서 시작된다고\\n할 수 있다. 이를 위해 본 연구는 한국어와 관련한\\n다양한 문제풀이 방식을 통해 6개의 LLM에 대한\\n성능을 평가 및 분석하였다. 세부적으로 한국어 구사\\n능력은야놀자의Bookworm모델이가장우수한것으로\\n나타났으며, 한국사, 한국 지리그리고 공무원 9급\\n시험 문제에서는 롯데정보통신의 LDCC-SOLAR\\n모델이 우수한 것으로 평가되었다.향후 LLM 기술은\\n산업별 응용에서 중요한 역할을차지할 것이며, 이를\\n위한 올바른 평가는 중요한 역할을 할 것으로 생각\\n된다. 이에 초거대 언어모델의 한국어 이해 능력을\\n평가하기 위한 다양한 데이터셋 구축 및 평가 지표에\\n대한 개발이 필요할 것으로 생각된다.\\n참고문헌\\n[1] S. Lim and S. Lee “Research Trends in\\nArtificial Intelligence Language Models ”,\\nInformation and Communication Magazine, Vol 40,\\nNo.3, pp.42-50, 2023.\\n[2] M. Shanahan“Talking about large language\\nmodels”, Communication of the ACM,Vol 67, No.\\n2, pp68-79, 2024.\\n[3] A. Vaswani, N. Shazeer, N. Parmar, J.\\nUszkoreit, L. Jones, A.N. Gomez et al.,“Attention\\nis AllYou Need”, Advances in Neural Information\\nProcessing Systems, pp5998-6008, 2017.\\n[4] J. Devlin, M. Chang, K. Lee, and K. Toutanova,\\n“BERT:Pre-training of Deep Bidirectional Transformers\\nfor Language Understanding”, North America\\nChaper of the Association for Computational\\nLiguistics, pp4171-4186, 2018.\\n[5] A, Radfordm J, Narasimhan, T. Salimans, and\\nI. Sutskever, Improving LanguageUnderstanding\\nby Generarive Pre-training, OpenAI, 2018\\n[6] LDCC. (2024, February 28). LDCC/LDCC\\n-SOLAR-10.7B. Hugging Face. https://hugging\\nface.co/LDCC/LDCC-SOLAR-10.7B\\n[7] Yanolja. (2024, March 16).Yanolja/Bookworm-\\n10.7B-v0.4-DPO. Hugging Face. https://hugging\\nface.co/yanolja/Bookworm-10.7B-v0.4-DPO\\n[8] Dopeornope. (2024, January 15). DopeorNope\\n/SOLARC-M-10.7B. HuggingFace. https://hugging\\nface.co/DopeorNope/SOLARC-M-10.7B\\n[9] Meta. (2023, November 13). Meta-Llama/Llama\\n-2-13b-Hf. Hugging Face. https://huggingface.co/\\nmeta-llama/Llama-2-13b-hf\\n[10] Heavytail. (2024, January 2 8). Heavytail/\\nKullm-Solar. HuggingFace. https://huggingface.co/\\nheavytail/kullm-solar\\n[11] Beomi.(2023,May 3).Beomi/KoAlpaca-Polyglot-12.8B.\\nHugging Face.\\n https://huggingface.co/beomi/\\nKoAlpaca-Polyglot -12.8B\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x006\\x00 \\x00-')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132be6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n63\\n요약\\n본 연구는 거대 언어 모델(Large Language Models, LLM)의 한국 이해도를 평가하\\n기 위해 설계된 Ko-Sovereign 벤치마크를 제안한다. Ko-Sovereign 벤치마크는 한국\\n어 능력 평가에만 초점을 맞추었던 기존 벤치마크의 한계를 극복하고, 법, 경제, 정치'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='어 능력 평가에만 초점을 맞추었던 기존 벤치마크의 한계를 극복하고, 법, 경제, 정치 \\n등 한국 특화 전문 지식을 포함한 총 9개의 평가 영역으로 범위를 확장하였다. 평가 지\\n표에는 유창성, 최신성, 사실성, 편향성, 문화 맥락 이해가 포함되며, 문항 유형은 빈칸 \\n채우기, 밑줄, 사실 확인, 순서나열, 정답매칭, 복합과 같은 형식으로 구성된다. 실험 결\\n과, ChatGPT4o는 전반적으로 높은 정확도를 달성했으며, EXAONE3 또한 한국적 지'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='식을 효과적으로 반영하는 성능을 보였다. Ko-Sovereign 벤치마크는 문화, 역사, 법 \\n등 다양한 한국적 영역을 종합적으로 평가할 수 있는 평가 프레임워크를 제안했다는 \\n점에서 의의가 있다.\\nABSTRACT\\nThis study introduces the Ko-Sovereign benchmark, designed to evaluate the \\nKorean comprehension capabilities of Large Language Models(LLMs). The Ko-'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='Sovereign benchmark addresses the limitations of previous benchmarks that \\nfocused solely on Korean language proficiency by expanding its scope to include \\nnine distinct evaluation domains, encompassing specialized knowledge in areas such'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='as law, economics, and politics. The evaluation metrics include fluency, recency, \\nfactuality, bias, and cultural context understanding, with question types structured \\ninto formats such as fill-in-the-blank, underline matching, fact verification,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='sequence ordering, answer matching, and complex tasks. Experimental results \\nindicate that ChatGPT4o achieved the highest overall accuracy, while EXAONE3 \\ndemonstrated strong performance in reflecting Korean-specific knowledge. The'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='Ko-Sovereign benchmark is a significant contribution, offering a comprehensive \\nframework for evaluating LLMs across diverse Korean-specific domains, including \\nculture, history, and law. \\n컴퓨터교육학회 논문지 2024년 제27권 제9호\\nhttps://doi.org/10.32431/kace.2024.27.9.007 거대 언어 모델의 한국 이해도 \\n평가를 위한 벤치마크 연구\\n*'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='평가를 위한 벤치마크 연구\\n*\\nBenchmark Study for Evaluating \\nthe Korean Comprehension of Large Language \\nModels\\n서민주† · 정연주† · 이현정† · 임혜균† · 장정선††\\nMinju Seo† · Yeonjoo Jeong† · Hyunjeong Lee† · Hyekyun Im† · Jungsun Jang††\\n주제어 생성형 인공지능, 인공지능 교육, 거대 언어 모델, 거대 언어 모델 평가, 한국형 벤치마크, 소버린 AI'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='Keywords  Generative AI, AI Education, Large Language Model, LLM Evaluation, Korean \\nBenchmark, Sovereign AI\\n†정회원\\n††정회원\\n고려대학교 대학원 역사학과 박사수료\\n고려대학교 문과대학 한국사학과 부교수\\n(교신저자)\\n논문투고\\n심사완료\\n게재확정\\n발행일자\\n2024년 11월 16일\\n2024년 12월 13일\\n2024년 12월 18일\\n2024년 12월 26일 \\n* \\x07본 논문은 KT의 지원을 받아 수행된 고려대학교-KT \\n산학공동연구 개발과제의 연구결과임.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n64\\n1. 서론\\n최근 지속적인 기술 혁신으로 인공지능은 인간의 지능 수\\n준에 필적하는 결과물을 생성하기에 이르렀다. 하지만 그 이\\n면에는 광범위한 인공지능 기술 활용으로 인한 허위 정보의 \\n확산, 딥페이크 등 새로운 사회 문제가 있으며, 국가 간 격\\n차를 심화시키는 요인으로까지 확장되고 있다. 인공지능 기'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='차를 심화시키는 요인으로까지 확장되고 있다. 인공지능 기\\n술의 위험성을 인식한 이래 각 국가는 자국의 디지털 주권\\n(Digital Sovereignty)을 구축하기 위해 노력하고 있다. 국\\n가와 개인이 자신들의 디지털 기술, 데이터, 인프라에 행사\\n하는 통제권을 의미하는 디지털 주권은 국가 안보, 국가 경\\n쟁력, 개인 사생활을 유지하기 위한 필수 조건이다[1]. 자국\\n의 인공지능 기술이 자국의 국가 정체성의 유지와 연결되는 \\n만큼 디지털 주권의 확보는 소버린(Sovereign) AI를 통해'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='만큼 디지털 주권의 확보는 소버린(Sovereign) AI를 통해 \\n가능하다[2]. 자국의 데이터와 인프라를 구축한 소버린 AI\\n는 자국의 디지털 역량, 나아가서는 자국의 이익을 강화하는 \\n중요한 수단이 될 것이다. 실제 2023년 한국 데이터로 훈련\\n하여 한국의 문화와 사회적 맥락을 이해하는 거대 언어 모델\\n이 개발되어 디지털 주권을 점유하려는 노력이 한국에서도 \\n본격적으로 시도되고 있다[3].\\n생성형 인공지능 기술의 발전에 따라 자연어 처리 분야\\n에 특화된 거대 언어 모델 역시 매개변수의 크기를 확대하'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='에 특화된 거대 언어 모델 역시 매개변수의 크기를 확대하\\n며 다양한 자연어 처리 작업을 수행하고 있다. OpenAI가 \\n개발한 Chat GPT 4o는 모의 변호사 시험에서 상위 10%\\n의 수준을 달성하여 전문적, 학문적 영역에서도 괄목할 만\\n한 성능의 향상을 이뤄냈다[4]. 이와 함께 거대 언어 모델\\n을 평가하는 벤치마크 데이터에 대한 논의도 활발하게 이\\n루어졌다. 전통적인 거대 언어 모델의 벤치마크 데이터로\\n는 ARC[5], HellaSwag[6], MMLU[7], TruthfulQA[8],'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='는 ARC[5], HellaSwag[6], MMLU[7], TruthfulQA[8], \\nWinogrande[9], GSM8k[10] 등이 있으며, 각 벤치마크는 \\n평가 주제와 난이도에 따라 거대 언어 모델의 다양한 측면\\n에 대해 평가하였으나 안전성을 평가하기에 부족하다는 비\\n판을 받았다. 게다가 고자원 언어인 영어를 대상으로 형성된 \\n벤치마크이기 때문에 영어를 포함한 다국어 모델이 아닌 이\\n상 벤치마크를 각 국가의 언어로 번역하여 평가하고 있어 각 \\n국가의 사회, 문화적 측면을 정확하게 평가할 수 없다는 한'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='국가의 사회, 문화적 측면을 정확하게 평가할 수 없다는 한\\n계가 있다. 하지만 벤치마크의 평가 결과를 토대로 거대 언\\n어 모델의 성능을 강화하는 방법을 모색한다는 점에서 거대 \\n언어 모델과 벤치마크는 선순환의 관계에 있다. \\n소버린 AI의 필요성이 증대되고 한국형 벤치마크 구축에 \\n관한 관심이 지속된 결과, 한국어를 기반으로 거대 언어 모\\n델 벤치마크 개발이 집중적으로 시도되고 있다. 이러한 현\\n상은 한국형 거대 언어 모델이 발전할 수 있는 기반을 제공\\n할 수 있다는 점에서 고무적이다. 초기 한국형 벤치마크는'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='할 수 있다는 점에서 고무적이다. 초기 한국형 벤치마크는 \\n고자원 언어인 영어를 기반으로 제작된 HellaSwag과 같\\n이 전통적인 벤치마크를 한국어로 번역한 것에서부터 시작\\n되었다[11-13]. 하지만 초기 한국형 벤치마크는 기존에 구축\\n된 영어 중심의 벤치마크를 한국어로 번역하는 단계에 머물\\n렀기에 한국의 문화 맥락이 반영되지 않는다는 한계가 존재\\n했다. 이러한 한계를 극복하고자 영어 기반 벤치마크를 한\\n국의 문화적 뉘앙스를 보존하여 번역하는 벤치마크 연구가 \\n진행되기도 했다[14]. 최근에는 HAE-RAE 벤치마크[15],'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='진행되기도 했다[14]. 최근에는 HAE-RAE 벤치마크[15], \\nCLIcK[16], KorNAT[17]과 같이 한국어를 기반으로 벤치마\\n크를 구축하려는 연구도 등장하는 추세이다. 각 연구는 거\\n대 언어 모델의 한국어 능력, 한국의 사회적 편향, 한국의 사\\n회적 가치와 상식 등을 다각도에서 평가하였으나 평가 영역\\n을 종합한 벤치마크의 필요성은 남아 있다. KMMLU는 생\\n물, 화학, 세법, 형법 등을 포함한 광범위한 종합 지식 벤치\\n마크로서 한국의 사회 문화 맥락을 반영하고자 도입되었다'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='마크로서 한국의 사회 문화 맥락을 반영하고자 도입되었다\\n[18]. 하지만 한국의 구체적이고 특수한 부분을 다룬 문항은 \\n약 20%에 불과하다.\\n본 논문은 한국형 벤치마크 연구에서 드러난 한계를 보완\\n하려는 시도로 시작되었다. 본 논문을 통해 거대 언어 모델의 \\n한국어 능력뿐만 아니라 한국의 사회문화적 맥락을 다양한 \\n분야에서 평가할 수 있는 벤치마크인 Ko-Sovereign을 제안\\n한다. 일차적으로 평가의 영역을 언어 및 문학, 역사, 문화 및 \\n민속, 법, 경제 및 금융, 정치, 지리, 사회, 교육의 9개로 세분'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='민속, 법, 경제 및 금융, 정치, 지리, 사회, 교육의 9개로 세분\\n화하였다. 한국어 능력 평가나 한국적 상식 평가 영역만을 제\\n한적으로 구축한 기존 벤치마크 연구와 차별되는 지점이다. \\n평가 영역의 확장에서 나아가 문항의 유형을 형식과 내용으\\n로 체계화하였다. 또한 거대 언어 모델을 평가하는 지표를 유\\n창성, 최신성, 사실성, 편향성, 문화 맥락 이해로 세분화하여 \\n한국형 거대 언어 모델의 역량을 종합적으로 측정할 수 있도\\n록 했다. 궁극적으로는 거대 언어 모델이 취약한 부분을 영역'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='록 했다. 궁극적으로는 거대 언어 모델이 취약한 부분을 영역\\n별, 기능별로 진단하여 보다 견고한 한국형 거대 언어 모델로 \\n성장할 수 있는 기반을 제공할 수 있도록 했다.\\n논문은 다음과 같은 순서로 구성하였다. Ⅱ장에서는 현재\\n까지 수행된 벤치마크, 소버린 AI, 한국형 거대 언어 모델 \\n벤치마크를 대상으로 축적된 관련 연구를 조망한다. Ⅲ장에\\n서는 본격적으로 본 논문에서 구축한 벤치마크의 구성을 평\\n가 영역, 문항 유형, 평가 지표의 순서로 검토한다. Ⅳ장에\\n서는 다국어 대규모 언어 모델과 한국어 특화 대규모 언어'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='서는 다국어 대규모 언어 모델과 한국어 특화 대규모 언어 \\n모델을 대상으로 진행한 실험 환경 및 방법을 서술한다. Ⅴ\\n장에서는 실험 결과를 분석적으로 제시하고, 이를 기반으로 \\nⅥ장에서 소버린 AI를 구현하기 위한 방향 및 거대 언어 모\\n델을 종합적으로 평가할 수 있는 벤치마크의 전망을 제시하\\n고자 한다. 본 논문이 한국형 거대 언어 모델 벤치마크의 발\\n전, 나아가 소버린 AI의 신속한 구현을 매개하는 데 일조하\\n기를 기대한다.\\n2. 관련 연구\\n2.1 소버린 거대 언어 모델'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='기를 기대한다.\\n2. 관련 연구\\n2.1 소버린 거대 언어 모델\\n소버린 AI는 각 국가의 자체 인프라와 데이터, 인력 및 \\n비즈니스 네트워크를 활용하여 각 국가의 언어와 문화, 가\\n치관 등을 반영한 AI를 의미한다[19], [20]. 즉 자국의 데이\\n터와 개발된 인공지능 기술에 대해 각국의 소유권을 강조\\n하는 개념이다[21]. AI가 사회 여러 분야에 혁신을 가져와'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n65\\n점점 AI의 중요도가 커지고 있는 상황에서 많은 국가가 AI\\n에 적극적으로 투자하고 있다. 2023년 하반기부터 생성 AI\\n는 미래 국가 경쟁력을 결정하는 핵심 요소로 간주되기 시\\n작했고, 경제적 이익과 새로운 세계질서 속의 리더십 선점\\n을 위해 각 국가에서 생성 AI 개발에 뛰어들고 있다[2]. 또'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='을 위해 각 국가에서 생성 AI 개발에 뛰어들고 있다[2]. 또\\n한 독립적으로 AI 역량을 쌓으려는 각국 기업의 움직임도 \\n성과를 보이고 있다[20].\\n소버린 AI 개발과 함께 디지털 주권의 개념도 논의가 시\\n작되고 있다. 디지털 주권이란 디지털 맥락에서 데이터, 소\\n프트웨어, 표준, 서비스 및 기타 디지털 인프라에 대한 정\\n당한 통제 권한의 형태이다[22]. 이러한 디지털 주권의 행\\n사는 소버린 AI와 결부되어 있다. 소버린 AI의 개발은 국가 \\n경쟁력, 미래의 세계질서 속 리더십 선점, 그리고 미국 빅테'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='경쟁력, 미래의 세계질서 속 리더십 선점, 그리고 미국 빅테\\n크의 생성 AI를 통한 문화종속을 피하고 국가 정체성을 지\\n키기 위한 노력의 결과로 해석할 수 있기 때문이다[2].\\n최근 GPT-4[4]와 Gemini[23] 등은 다양한 분야에서 뛰\\n어난 성능을 보였으나, 대부분의 거대 언어 모델은 영어\\n를 기반으로 하기 때문에 영어 텍스트의 이해와 생성, 그\\n리고 영어를 사용하는 사회의 문화와 규범 등에서 뛰어난 \\n성능을 보인다. 반면 저자원 언어와 해당 국가의 문화 등\\n에 대해서는 성능이 떨어진다. 이로 인해 현재 대부분의'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='에 대해서는 성능이 떨어진다. 이로 인해 현재 대부분의 \\nAI와 거대 언어 모델은 다양한 언어 및 문화에 대한 포용\\n성이 낮다는 한계가 있다. 따라서 미국을 제외한 국가에\\n서 인프라, 언어, 데이터 등을 모두 통제할 수 있는 소버\\n린 거대 언어 모델의 개발이 대두되고 있다. 한국에서는 \\nChatGPT-3의 학습데이터에서 한국어 비중이 0.016%에 \\n불과하여 한국어 성능이 떨어지는 한계를 수정하기 위해 \\nHyperCLOVA-X를 발표하였다[24]. 한국어, 영어, 코드데\\n이터를 학습한 후 주석이 달린 데이터로 인스트럭션 튜닝'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='이터를 학습한 후 주석이 달린 데이터로 인스트럭션 튜닝\\n을 거치는 방식을 활용하였다[3].\\nUAE에서는 아랍어와 영어로 훈련하여 아랍어 중심 거\\n대 언어 모델인 Jais와 Jais-chat을 공개하였다[25]. 핀란\\n드의 Silo AI 역시 핀란드어, 영어, 프로그래밍 언어로 훈\\n련한 Poro를 개발하였다[26]. 인도의 Krutrim AI에서는 \\n인도의 20가지 언어를 이해하고 10가지 언어를 생성할 수 \\n있는 거대 언어 모델 Krutrim을 제작하였고, 중국에서는 \\n문샷 AI에서 챗봇 Kimi를 제공하고 있다. 일본 NTT에서'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='문샷 AI에서 챗봇 Kimi를 제공하고 있다. 일본 NTT에서\\n는 츠즈미를 공급하고 있으며, 파나소닉에서도 거대 언어 \\n모델 개발을 발표한 상황이다. 영국에서는 BritGPT, 그리\\n고 대만은 정부 주도하에 Taide를 준비하고 있으며, 이탈\\n리아의 Fast Web, 인도의 Reliance Industries, 독일의 \\nAleph Alpha에서도 각기 자국 언어 거대 언어 모델을 개\\n발 중에 있다[20].\\n한편 디지털 주권에 대해 전통적인 국가 중심의 정의에\\n서 벗어나 EU와 같이 국제적 또는 초국가적 기관이 권위'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='서 벗어나 EU와 같이 국제적 또는 초국가적 기관이 권위\\n를 가질 수 있음을 인정한 연구가 있다[27]. 그렇기 때문에 \\n소버린 AI와 거대 언어 모델에 대해서 국제적 또는 초국가\\n적 거대 언어 모델을 검토할 필요가 있다. 대표적으로 싱가\\n포르에서 공개한 동남아시아 언어와 문화를 반영한 소버린 \\n거대 언어 모델 SEA-LION[28]이 있다. 이 외에 프랑스의 \\n스타트업 Mistral AI는 자체 개발한 Mistral Large 모델\\n을 기반으로 Le chat을 공개하였는데[20], 이는 EU 국가'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='을 기반으로 Le chat을 공개하였는데[20], 이는 EU 국가\\n의 언어와 문화를 기반으로 한 소버린 거대 언어 모델이다.\\n이상의 연구 결과에 의하면 소버린 거대 언어 모델의 개\\n발은 국가 자체적으로 진행하고 있고, 동남아시아나 EU \\n등에서는 단일 국가가 아닌 초국가적 단위로 이루어지고 \\n있는 경우도 확인된다. 이러한 영어 이외 언어 모델의 문제\\n점은 높은 비용이다. 소버린 거대 언어 모델은 특정 국가\\n를 대상으로 하므로 미국 빅테크 기업에 비해 비용이나 인\\n프라가 부족한 경우가 많다. 그리고 언어 자원이 적은 경우'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='프라가 부족한 경우가 많다. 그리고 언어 자원이 적은 경우\\n가 대다수여서 학습 데이터를 마련하기 어렵다는 문제도 \\n있다. 거대 언어 모델 학습에 필요한 데이터 크기가 증가하\\n는 상황 속에서 다국어 데이터 추가로 모델 용량이 제한되\\n어 저자원 언어와 고자원 언어 모두 성능이 저하되는 ‘다국\\n어의 저주’ 현상이 나타나기도 한다. 그렇기 때문에 대규모 \\n다국어 사전 학습이 아닌 타겟화 된 모델을 사용하면 성능\\n이 향상될 것으로 짐작된다[29].\\n이러한 소버린 AI 기술을 국가나 기업이 자체적으로 개'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='이러한 소버린 AI 기술을 국가나 기업이 자체적으로 개\\n발하면 보안 문제와 기술 의존도를 낮춰 안전성을 높일 수 \\n있다. 그에 따라 기술 수출 및 기술 이전에 대한 제약을 줄\\n여 국가와 기업의 경쟁력을 강화하며 경제적 이익을 창출\\n할 수 있다[20]. 또한 자국어 혹은 특정 지역의 언어만을 \\n대상으로 학습시키는 소버린 거대 언어 모델의 개발은 각 \\n국가 및 지역의 디지털 주권을 지키고 디지털 권력에서의 \\n배제를 방지하며, 저자원 언어를 활성화하고 보존할 것이\\n다. 따라서 소버린 AI와 거대 언어 모델에 대한 개발과 연'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='다. 따라서 소버린 AI와 거대 언어 모델에 대한 개발과 연\\n구가 필요하며, 그를 위해 본 논문에서는 소버린 거대 언어 \\n모델의 성능을 평가하기 위한 연구를 진행하였다.\\n2.2 거대 언어 모델 벤치마크\\n근래 거대 언어 모델의 개발과 활용이 많은 관심을 받으\\n면서 거대 언어 모델을 평가하는 일도 한층 중요해졌다. 거\\n대 언어 모델 벤치마크의 역할은 거대 언어 모델의 성능\\n을 측정하고, 평가하는 것이다[30]. 자연어처리 기술의 분\\n야별 벤치마크 연구에 이어 점차 언어별 벤치마크 데이터'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='야별 벤치마크 연구에 이어 점차 언어별 벤치마크 데이터\\n가 공개되었다. 영어 언어 모델 벤치마크 GLUE[31], 중국\\n어 언어모델 벤치마크 CLUE[32], CLUE의 한계를 보완\\n한 SuperGLUE[33], 최초의 한국어 언어 모델 벤치마크 \\nKLUE[12] 등이 대표적인 사례이다. \\n거대 언어 모델 벤치마크는 특정 영역을 정해 다양한 대\\n규모 언어모델의 성능을 비교하는 방향으로 발전하였고, \\nARC, HellaSwag, MMLU, TruthfulQA, Winogrande,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='ARC, HellaSwag, MMLU, TruthfulQA, Winogrande, \\nGSM8k 등이 대표적으로 평가에 활용되고 있다. ARC(AI2 \\nReasoning Challenge)는 추론 능력을 평가하기 위한 벤\\n치마크이다. 초등학교와 중학교 수준의 과학 문제 7,787개\\n로 구성되어 있고, 답변이 얼마나 적절한지를 측정한다. 도\\n전적인 벤치마크 데이터와 쉬운 벤치마크 데이터가 구분되\\n어 있는 것이 특징이다[5]. WinoGrande는 상식 추론을 평'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n66\\n가하기 위한 벤치마크로, 크라우드 소싱(crowdsourcing)\\n으로 수집한 44,000개의 문제로 구성되어 있다. 주로 대명\\n사를 정확하게 맞추는지 확인할 수 있다[9]. MMLU는 언어 \\n이해를 다루는 벤치마크로, 초등 수학, 미국 역사, 컴퓨터 \\n과학, 법률 등을 포함한 57개의 영역을 난이도별로 출제하'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='과학, 법률 등을 포함한 57개의 영역을 난이도별로 출제하\\n고, 다수 영역의 질문에 대해 얼마나 정확한 답변을 도출하\\n는지 살펴볼 수 있다[7]. HellaSwag은 상식 능력을 평가하\\n기 위한 벤치마크로 WikiHow와 ActivityNet에서 수집한 \\n총 70,000개의 문제로 구성되어 있다. 미완성된 구절을 완\\n성하게 하는 방식으로 평가한다[6]. TruthfulQA는 모델의 \\n답변이 거짓인지 진실인지를 판별하는 벤치마크로, 건강, \\n법률, 금융, 정치 등 38개 영역의 817개의 질문으로 구성되'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='법률, 금융, 정치 등 38개 영역의 817개의 질문으로 구성되\\n어 있으며, 잘못된 믿음이나 오해로 인해 사람이 오답을 말\\n하기 쉬운 내용으로 짜여있다[8]. GSM8k는 수학적 추론을 \\n측정하는 벤치마크로, 학년별 다양한 난이도의 수학 문제 \\n8,500개로 구성되어 있다[10].\\n이러한 벤치마크는 거대 언어 모델의 다양한 측면을 평\\n가하는 데 일조하였다. 그러나 기존 벤치마크는 각 국가의 \\n고유한 문화 맥락을 반영하지 못했다는 한계가 있다[34, \\n35]. ARC, HellaSwag, MMLU, TruthfulQA 등 4가지'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='35]. ARC, HellaSwag, MMLU, TruthfulQA 등 4가지 \\n벤치마크는 한국어로 번역되었지만[36] 기계 번역을 이용\\n했기 때문에 한계가 분명하다. 또한 미국 중심의 문화 및 \\n상식이 반영된 벤치마크이기 때문에, 이를 이용하여 한국\\n의 정치, 경제, 문화 등의 측면을 정확히 평가하기 어렵다\\n는 문제가 있다.\\n하지만 비용 등의 문제로 영어 중심의 벤치마크를 번\\n역하여 평가에 사용하는 연구가 다수 진행되어 왔다. \\nKorean-NLI & STS[11]는 자연어 추론(NLI)과 의미 텍'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='Korean-NLI & STS[11]는 자연어 추론(NLI)과 의미 텍\\n스트 유사성(STS)을 위해 영어 데이터를 번역한 자료로, \\n한국어 특유의 뉘앙스를 반영하지 못할 가능성이 있다. \\nKLUE[12]는 GLUE 벤치마크에 한국어를 적용한 것이\\n다. 주제 분류, 의미 텍스트 유사성, 자연어 추론 등 다양\\n한 작업을 포함하지만, 번역이나 특정 작업 중심이어서 언\\n어 특화 모델을 평가하기에 충분하지 않다. KoBEST[13]\\n는 COPA[37], WiC[38], BOOLQ[39], HellaSwag,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='는 COPA[37], WiC[38], BOOLQ[39], HellaSwag, \\nSentiNeg[40] 등을 한국어로 재구현한 것으로 한국어의 \\n고유한 뉘앙스를 충분히 반영하지 못한다.\\n한편 고자원 언어인 영어 데이터를 기반으로 학습한 거\\n대 언어 모델의 한계에 대한 연구도 다수 진행되었다. 그 \\n결과는 크게 7가지로 분류된다. 첫 번째는 상식왜곡이다. \\n지리적 다양성에 따라 상식의 범위와 내용이 달라질 수 있\\n으며[34], 학습된 언어에 따라 각 문화의 사실 상식이 왜곡'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='으며[34], 학습된 언어에 따라 각 문화의 사실 상식이 왜곡\\n되거나 편향될 수 있다는 것이다[41]. 두 번째는 상식 암기\\n이다. 거대 언어 모델은 사전 학습 과정에서 데이터를 암기\\n하는 경향이 있으며[42], 상식 지식 형성은 관계의 빈도와 \\n복잡성에 영향을 받아 단순한 추론과 공출 현상에 기반하\\n는 경향이 있다고 설명된다[43]. 세 번째는 유해한 발화이\\n다. 사회적, 문화적 요소가 학습 데이터에 영향을 미쳐 편\\n향이나 공격성이 포함될 가능성이 있다고 보았다[44, 45].'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='향이나 공격성이 포함될 가능성이 있다고 보았다[44, 45]. \\n네 번째는 문법성이다. 표현을 위해 일반적인 문법적 이해\\n가 필요하며, 상식을 반영하는 완전한 문장 구성을 위해 각 \\n언어에 대한 문법적 교정이 필요하다[46-48]. 다섯 번째는 \\n타당성이다. 거대 언어 모델의 생성 결과가 구체적인 지식\\n을 검색하는 것이 아니라 암묵적이고 모호한 추론을 통해 \\n생성한다는 문제가 있다[49, 50]. 여섯 번째는 수치적 상식\\n인데, 언어 모델은 상식 범위 내에서 수치 정보를 처리하는'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='인데, 언어 모델은 상식 범위 내에서 수치 정보를 처리하는 \\n데 약하다[47, 51]. 마지막은 속담이다. 관용 표현은 언어 \\n모델에게 어려운 영역이며, 상식 지식 그래프를 통해 해결\\n하려는 시도가 이루어졌다[52]. 그러므로 각 국가의 언어, \\n문화, 사회, 역사 등의 지식 이해도와 생성 능력을 평가하\\n기 위한 벤치마크를 구축해야 한다.\\n2.3 한국형 거대 언어 모델 벤치마크\\n이러한 문제 해결을 위해 한국의 사회문화적 맥락\\n과 상호작용할 수 있는 한국어 상식 추론 벤치마크인'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='과 상호작용할 수 있는 한국어 상식 추론 벤치마크인 \\nKoCommonGENv2가 제안되었다[53]. 또한 영어 데이터\\n로 학습된 거대 언어 모델의 단점을 극복하기 위해 HAE-\\nRAE Bench가 제시되었다[54]. 평가 결과, 한국어 모델이 \\n다국어 모델보다 우수한 성능을 보였다. 한국어 지식을 평\\n가한 연구로 KoBBQ가 있다[14]. 한국 문화가 접목된 벤치\\n마크를 제안하고, 한국의 상황과 사회적 편향을 반영하였\\n다. KorFin-ASC[15]는 한국어 뉴스 데이터를 기반으로 하'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='다. KorFin-ASC[15]는 한국어 뉴스 데이터를 기반으로 하\\n는데, 주로 금융 도메인에서의 감정 분류에 집중하여 좁은 \\n범위를 대상으로 한 벤치마크를 제안하였다. KMMLU[18]\\n는 한국어 시험에서 수집한 45개 영역 35,030개의 문제로 \\n구성되어 있으나, 한국의 구체적이고 특수한 부분을 다룬 \\n문항은 약 20%에 지나지 않는다. \\n기존 한국어 거대 언어 모델 벤치마크 연구는 연구 대상\\n의 범위가 포괄적이지 못하다는 한계가 있다. 따라서 본 논\\n문에서는 이러한 한계점을 보완하는 방향으로 한국형 벤치'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='문에서는 이러한 한계점을 보완하는 방향으로 한국형 벤치\\n마크에 대한 연구를 진행하고자 한다.\\n3. 한국형 거대 언어 모델 역량 평가 벤치마크\\n3장에서는 한국형 거대 언어 모델의 역량을 평가하기 위\\n해 벤치마크의 구성을 평가 영역, 문항 유형, 평가 지표의 순\\n서로 검토한다. 난이도 변인을 분석한 연구에 따르면 전 영\\n역에 걸쳐 나타나는 난이도의 공통적인 변인은 내용적 측면\\n과 형식적 측면으로 구분된다[55]. 평가의 방식 또한 내용과 \\n형식으로 분리할 수 있다고 판단하여 본 논문에서는 내용적'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='형식으로 분리할 수 있다고 판단하여 본 논문에서는 내용적 \\n평가에 상응하는 평가 영역, 형식적 평가에 해당하는 문항 \\n유형을 설정하였다. 평가 영역에서는 ‘한국적’인 것의 내용\\n을 구체화하기 위해 영역을 9가지로 세분화하였다. 형식적 \\n측면은 문제를 출제하는 방식으로 구현되며, 6가지의 문항 \\n유형으로 확인할 수 있다. 마지막으로 평가하고자 하는 평가 \\n주안점에 따라 평가 지표를 5가지로 정립하였다. 각 절에서\\n는 본 논문이 제안하는 벤치마크 데이터셋의 사례를 제시하\\n여 벤치마크의 구성을 시각적으로 파악할 수 있도록 하였다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n67\\n3.1 평가 영역\\n본 논문에서는 한국어 능력, 한국의 현행 정책, 한국의 \\n실생활 경험 등을 포함한 종합적 평가를 진행한다. 한국 사\\n회에 대한 이해도는 한국어뿐만 아니라 한국 사회 전반에 \\n대한 이해 수준을 함께 고려해야 하기 때문이다. 한국 사회\\n의 이해도를 시험과 같은 비교적 객관적 형태로 평가할 수'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='의 이해도를 시험과 같은 비교적 객관적 형태로 평가할 수 \\n있는 방법에는 외국인의 한국 귀화 시험이 있다. 외국인이 \\n한국 국적을 취득할 때 필수적으로 요구되는 한국 귀화 필\\n기 시험은 한국어 능력 시험, 한국 사회 이해 능력 시험 2\\n가지로 구성된다[56]. 외국인이 한국 귀화 시험에서 요구\\n되는 능력을 갖추면 한국 국적을 취득할 수 있는 것과 마찬\\n가지로 거대 언어 모델이 한국어와 한국 사회에 대한 이해\\n도를 평가하는 시험에서 기준 이상의 점수를 획득하면 한\\n국형 거대 언어 모델로서의 역량을 갖추었다고 전제한다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='국형 거대 언어 모델로서의 역량을 갖추었다고 전제한다.\\n본 논문은 현행 한국 귀화 시험의 영역 구분을 기반으로 \\n세부 영역을 Table 1과 같이 재구성하였다. 수학이나 과\\n학과 같이 보편적인 지식 분야는 국가별 특성이 약하므로\\n[17], 소버린 AI의 평가와 거리가 멀다고 판단하여 평가 영\\n역에서 제외하였다.\\nTable 1. Benchmark Evaluation Area\\nEvaluation Area Detailed Area\\nLanguage \\n&Literature\\nNon-fiction (expository writing,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='&Literature\\nNon-fiction (expository writing, \\nargumentative essays, personal essays, reports), \\nSpeech (spoken communication situations, \\ndialects), Grammar, Literature (poetry, novels, \\nprose, plays), Others\\nHistory\\nPrehistoric Era, Gojoseon and Various States,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='Prehistoric Era, Gojoseon and Various States, \\nThree Kingdoms Period, Unified Silla and \\nBalhae Period, Goryeo Dynasty, Joseon \\nDynasty, Japanese Occupation Period, Modern \\nHistory, Historical Figures of Korea, Korean \\nCultural Heritage, Integrated Korean History, \\nOthers\\nCulture&Folklore'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='Others\\nCulture&Folklore\\nTraditional Values, Traditional Food, Clothing, \\nand Housing, Rituals, Holidays, Religion, \\nPopular Culture, Leisure Culture, Intangible \\nHeritage, Commemorative Days, Others\\nLaw\\nConstitution, Property Relations and Law, \\nFamily Relations and Law, Social Life and'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='Family Relations and Law, Social Life and \\nLaw, Crime and Punishment, State and \\nInstitutions and Law, Everyday Laws, Others\\nEconomy&Finance Everyday Life, Economic Activities, Economic \\nPolicy, Financial Knowledge, Others\\nPolitics\\nKorean Democratic Politics, Legislative'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='Politics\\nKorean Democratic Politics, Legislative \\nBranch, Judicial Branch, Executive Branch, \\nElections and Local Autonomy, Civil \\nMovements, Others\\nGeography\\nClimate, Topography, Population, \\nTransportation, Capital Region (Seoul, \\nGyeonggi) and Provinces (Chungcheong,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='Gyeonggi) and Provinces (Chungcheong, \\nJeolla, Gyeongsang, Gangwon, Jeju), Others\\nSociety\\nKorean Symbols, Family, Workplace, \\nTransportation and Communication, Housing, \\nUrban and Rural Areas, Welfare, Healthcare \\nand Safety, Others\\nEvaluation Area Detailed Area\\nEducation'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='Evaluation Area Detailed Area\\nEducation\\nEarly Childhood Education, Elementary \\nSchool, Middle School, High School, \\nUniversity, Graduate School, Lifelong \\nEducation, Alternative Education, Others\\n각 영역에 따라 기대하는 거대 언어 모델의 역량은 다음\\n과 같다.\\n(1) 언어 및 문학\\n\\t \\t문항의 내용을 이해하고, 적절한 어휘로 바꾸어 요약\\n할 수 있다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='문항의 내용을 이해하고, 적절한 어휘로 바꾸어 요약\\n할 수 있다.\\n\\t 담화의 맥락을 파악하여 의사소통할 수 있다.\\n\\t 표준어와 지역의 방언을 이해한다.\\n\\t \\t한국어의 문법 구조를 이해하고 문법에 적합한 글쓰\\n기가 가능하다.\\n(2) 역사\\n\\t \\t논란의 여지가 있거나 민감한 역사적 문제에 대해 \\n편향된 시각을 갖지 않는다.\\n\\t \\t역사적 사건이나 인물에 대한 주관적 판단을 피하고 \\n객관적 정보를 제공한다.\\n\\t \\t문화유산, 역사 해석 등 변화가 발생하는 영역에 대\\n해 변화를 반영한 정보를 제공한다.\\n(3) 문화 및 민속'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='해 변화를 반영한 정보를 제공한다.\\n(3) 문화 및 민속\\n\\t \\t문화 및 민속의 형성 배경과 현재 시행 모습을 이해\\n한다.\\n\\t \\t지역과 시기에 따른 다양한 문화 및 민속을 이해한다.\\n\\t \\t문화와 민속에 내재한 각각의 고유성을 인정하고 편\\n향된 시각을 갖지 않는다.\\n(4) 법 \\n\\t \\t여러 분야의 법에 대한 최신 정보 및 정확한 정보를 \\n제공한다. \\n\\t \\t법률 지식을 전달할 때는 윤리적이고 중립적인 태도\\n를 유지한다. \\n\\t \\t일상 용어와 법률 용어를 매끄럽게 변환한다. \\n\\t \\t제시된 상담 사례 및 판례에 대한 쟁점 및 요점을 전'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='제시된 상담 사례 및 판례에 대한 쟁점 및 요점을 전\\n달한다. \\n(5) 경제 및 금융\\n\\t \\t한국의 경제정책 변화와 그에 따른 영향 및 경제 상\\n황에 대한 최신 정보와 정확한 정보를 전달한다. \\n\\t \\t경제정책 및 경제 상황을 설명할 때 중립적인 태도\\n를 유지한다. \\n\\t \\t일생에 필요한 경제 지식에 대해 정확한 정보를 전\\n달한다. \\n(6) 정치\\n\\t \\t한국의 정치제도 변천과 현행 실태를 파악한다. \\n\\t \\t중앙과 지방의 정치 운영을 이해한다. \\n\\t \\t현재까지의 정치적 이슈와 지역 갈등을 중립적으로 \\n다룬다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n68\\n(7) 지리 \\n\\t \\t한국의 지리적 특성에 관한 정확한 정보를 제공한다. \\n\\t \\t한국 각 지역의 고유한 지리적, 문화적 특성을 이해\\n한다. \\n\\t \\t현대 한국의 지리적 특성이 경제, 사회, 환경에 미치\\n는 영향을 설명한다.\\n(8) 사회\\n\\t \\t현재 한국 사회에서 논의되고 있는 문제 또는 발생'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='는 영향을 설명한다.\\n(8) 사회\\n\\t \\t현재 한국 사회에서 논의되고 있는 문제 또는 발생\\n한 사건의 내용과 그에 대한 다양한 입장을 충분히 \\n이해한다. \\n\\t \\t한국 사회 전반에 대한 정확한 사실을 제공한다. \\n\\t \\t한국 사회의 관습과 특징을 이해한다. \\n(9) 교육 \\n\\t \\t한국 정부의 교육 정책에 따른 학교 제도, 교육 시스\\n템 등에 대한 정확한 정보를 제공한다. \\n\\t \\t한국의 문화적 배경과 관련지어 교육 정책과 교육 \\n환경에 대해 이해한다. \\n\\t \\t대학입시제도 등의 교육 정책과 교육 제도 내 특정'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='환경에 대해 이해한다. \\n\\t \\t대학입시제도 등의 교육 정책과 교육 제도 내 특정 \\n배경의 사용자에 편향되지 않는 전체적 정보를 제공\\n한다.\\n3.2 문항 유형\\n본 논문에서 구축한 벤치마크는 4개의 선지에서 정답을 \\n선택하는 객관식 사지선다의 형태이다. 문항의 형식은 ‘문\\n제-지문-보기’의 세 부분으로 나뉜다. 문제는 답을 생성하\\n기 위한 부가 설명 또는 해설과 문제 해결 방법을 지시하\\n는 지시부(instruction)로 구성된다. 예를 들어 ‘빈칸에 들\\n어갈 가장 적합한 단어를 보기에서 고르시오.’는 부가 설'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='어갈 가장 적합한 단어를 보기에서 고르시오.’는 부가 설\\n명 없이 지시부만 있는 문제이다. 지문은 문제를 풀기 위해 \\n제시된 부연 설명 부분으로, 문제에 따라 선택적으로 제공\\n된다. 보기는 1번부터 4번까지 정답과 오답이 혼재된 선지 \\n전체를 의미한다. 실험 대상이 되는 거대 언어 모델은 문제\\n를 확인하고, 지문을 읽으며, 보기에서 정답을 선택하는 과\\n정을 거치게 된다. 또한 문제의 지시부에 ‘모두’를 표기하\\n여 복수정답 여부를 명시하는 경우 복수정답도 가능하도록 \\n구성하였다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='여 복수정답 여부를 명시하는 경우 복수정답도 가능하도록 \\n구성하였다.\\nTable 2의 문제-보기 유형과 문제-지문-보기 유형 예시\\n를 통해 문항의 형식을 확인할 수 있다. 문제-보기는 문항\\n의 필수적 구성 요소이며 지문은 선택적으로 활용된다.\\nTable 2. Examples of Question Type\\nQ-O Type Q-P-O Type\\nQuestion\\nSelect all the incorrect \\nstatements regarding \\nmembers of the National \\nAssembly.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='members of the National \\nAssembly.\\nChoose the correct pair of \\nwords to fill in the blanks.\\nPassage\\nThe 6 years of elementary \\nschool and ( ) years \\nof middle school are \\nprovided as a ( ) period of \\nfree education.\\nQ-O Type Q-P-O Type\\nOptions\\n1.  On December 28, 2007, \\nan amendment changed'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='1.  On December 28, 2007, \\nan amendment changed \\nthe number of Supreme \\nCourt Justices to 13, \\nexcluding the Chief \\nJustice.\\n2.  On December 4, \\n1987, an amendment \\nreinstated the title \\n‘Supreme Court Justice’ \\nand changed the \\nnumber of justices to \\n13, excluding the Chief \\nJustice.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='13, excluding the Chief \\nJustice.\\n3.  On December 15, 2005, \\nan amendment changed \\nthe number of Supreme \\nCourt Justices to 12, \\nexcluding the Chief \\nJustice.\\n4.  On January 29, 1981, \\nan amendment changed \\nthe number of Supreme \\nCourt judges to 12, \\nexcluding the Chief \\nJustice.\\n1. 3,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='excluding the Chief \\nJustice.\\n1. 3, \\nCompulsory Education\\n2. 6, \\nCompulsory Education\\n3. 3, \\nPaid Education\\n4. 3, \\nNon-Compulsory \\nEducation\\n본 논문에서는 형식에 따른 문항 유형을 빈칸채우기, 밑줄, \\n사실확인, 순서나열, 정답매칭, 복합의 6가지로 정의하였다. \\n빈칸채우기는 빈칸에 들어갈 적절한 내용을 추론하여 문제\\n를 해결하는 유형이다. 밑줄은 밑줄이 있는 단어나 문장의 의'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='를 해결하는 유형이다. 밑줄은 밑줄이 있는 단어나 문장의 의\\n미를 고려하여 정답을 찾는 유형이다. 거대 언어 모델의 프롬\\n프트에 글자와 함께 밑줄을 입력할 수 없으므로 밑줄이 있는 \\n부분의 단어나 문장을 ‘해당 건물’과 같이 작은 따옴표를 붙\\n여 문제를 정확하게 파악할 수 있도록 수정하였다. 다만 형식\\n상의 문제 유형 구분에 가장 직관적이라고 판단하여 ‘밑줄 유\\n형’이라는 명칭을 그대로 사용한다. \\n사실확인은 문제가 요구하는 지시 사항에 가장 적합한(또\\n는 부적합한) 내용을 선택하는 유형이다. 예컨대 ‘가장 적절'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='는 부적합한) 내용을 선택하는 유형이다. 예컨대 ‘가장 적절\\n한 설명을 고르시오.’ 또는 ‘가장 부적합한 서술을 고르시오.’\\n가 있다. 순서나열은 문제에서 지정한 기준에 따라 지문의 각 \\n항목을 순서대로 나열하여 정답을 찾는 유형이다. 시기순 나\\n열, 맥락에 따른 문장 나열, 과정 순서의 나열 등의 문항이 출\\n제될 수 있다. 정답매칭은 지문에 무작위로 배치된 항목을 관\\n련 있는 것끼리 연결하는 형태의 문항 형식이다. 복합은 이상\\n에서 서술한 5개 유형이 2개 이상 활용된 유형을 의미한다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='에서 서술한 5개 유형이 2개 이상 활용된 유형을 의미한다. \\n예컨대 빈칸이 있는 지문을 주고, ‘해당 빈칸에 들어갈 단어\\n에 대한 설명으로 옳은 것을 고르시오.’와 같은 문항은 빈칸\\n채우기와 사실확인이 결합한 유형이므로 복합유형이라고 지\\n칭할 수 있다.\\n형식에 따른 문항 유형의 예시는 Table 3에 있다. 복합유\\n형은 결합되는 유형에 따라 문항이 상이한데, Table 3의 복\\n합 유형은 빈칸채우기와 사실확인이 결합한 사례이다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n69\\nTable 3. Examples by Question Type - Format\\nType Example\\nFill-in-the-\\nBlank\\nChoose the correct word to fill in the blank.\\n \\nTo address the undervaluation of the domestic stock'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='market and enhance shareholder value, the Korean \\ngovernment initiated the ( ) program in 2024.\\n1. K-Stock Activation\\n2. Corporate Value-Up-Correct  \\n3. Bubble\\n4. Giant-step\\nUnderline\\nThe following is part of a conversation between \\nYeongho, Minsu, and Jingu on their way home from'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='Yeongho, Minsu, and Jingu on their way home from \\nschool. Choose the one instance of ‘our’ that has a \\ndifferent meaning.\\nYeongho: Can we play at ㄱ.‘our’ house today? \\nㄴ.‘Our’ mom bought a delicious cake. \\nMinsu: Really? I have time before going to my'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='Minsu: Really? I have time before going to my \\nacademy, so let’s go together. Jingu, let ㄷ.‘us’ go \\ntogether. \\nJingu: Great. Then we’ll also get to see Sujin, whom \\nYeongho always calls ㄹ.‘our’ little sister and dotes \\non.\\n1. ㄱ   2. ㄴ   3. ㄷ-Correct   4. ㄹ\\nFact-\\nChecking'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='1. ㄱ   2. ㄴ   3. ㄷ-Correct   4. ㄹ\\nFact-\\nChecking\\nChoose the incorrect statement regarding the \\ndifferences in investigative authority between the \\nprosecution and the police.\\n1. When an investigation begins through a complaint \\nor accusation, the police make a decision on'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='or accusation, the police make a decision on \\nforwarding or not forwarding the case, while the \\nprosecution decides whether to indict or not indict \\nthe forwarded case.\\n2. The prosecution can be involved in the \\ninvestigation phase at the police level.-Correct'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='investigation phase at the police level.-Correct\\n3. If a warrant is required during the police \\ninvestigation stage, the prosecutor is involved.\\n4. If the police determine that there is no suspicion \\nof a crime after the investigation, they can decide not'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='to forward the case and exercise primary authority \\nto close the investigation.\\nOrdering\\nChoose the option that correctly arranges the events \\nrelated to the opening of Joseon’s ports in order.\\nㄱ. Japan sent ships to Joseon, modeling its \\ndiplomatic approach after the United States'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='diplomatic approach after the United States\\nㄴ. A treaty was signed that, for the first time, \\nincluded provisions on tariffs and mediation. \\nㄷ.  A treaty was concluded with a country where \\nnegotiations had been delayed due to issues related \\nto the recognition of Catholicism.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='to the recognition of Catholicism.\\nㄹ. It was agreed to open not only Busan but also \\ntwo other ports.\\n1. ㄱ-ㄹ-ㄴ-ㄷ-Correct\\n2. ㄱ-ㄷ-ㄹ-ㄴ \\n3. ㄹ-ㄷ-ㄱ-ㄴ          \\n4. ㄷ-ㄱ-ㄴ-ㄷ\\nType Example\\nAnswer \\nMatching\\nChoose the option that pairs A, B, and C with (가), \\n(나), and (다) in the most natural way.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='(나), and (다) in the most natural way.\\nA. Chungju B. Cheongju C. Gongju\\n(가) The local government’s YouTube channel \\nrecently became a major topic. \\n(나) The Chungcheongnam-do History Museum is \\nlocated there. \\n(다) The King Sejong and Chojeong Mineral Water \\nFestival takes place in October.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='Festival takes place in October.\\n1. A-(나)   2. B-(나)   \\n3. C-(다)   4. A-(가)-Correct\\nComplex\\nChoose the correct word to fill in the blank and the \\ncorrect description paired with the type of middle \\nschool.\\nMiddle schools are classified into general middle \\nschools and ( ) middle schools.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='schools and ( ) middle schools.\\n1. National, admission is through a separate \\nselection process.\\n2. Specialized, assigned to a location near home.\\n3. Private, offers career exploration education.\\n4. Specialized, educates students with talents in \\nspecific fields.-Correct\\n3.3 평가 지표'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='specific fields.-Correct\\n3.3 평가 지표\\n평가 지표는 모델 개발의 방향성을 안내하고, 거대 언어 \\n모델의 발전 수준을 평가하는 정량적 도구이다[57]. 효과\\n적인 평가 지표는 모델 출력에서 모델의 역량을 설명하고, \\n모델의 결함을 진단하며, 다양한 모델의 강점과 약점을 비\\n교하는 데 유용하게 작용하기 때문에[58] 적절한 평가 지\\n표의 설정이 중요하다. 자연어 생성 분야에서는 주요 평가 \\n지표로 유창성, 사실성, 다양성을 제시한다[59]. 즉 생성된 \\n텍스트가 맥락적으로 잘 구성되어야 하고, 의미를 잘 표현'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='텍스트가 맥락적으로 잘 구성되어야 하고, 의미를 잘 표현\\n해야 하며, 최대한 다양한 단어를 활용해 생성해야 높은 성\\n능을 갖는 모델로 간주할 수 있다. \\n본 논문에서는 기존 자연어 생성 분야의 평가 지표를 수\\n용하여 완결성과 다양성의 측면에서 유창성으로, 의미 표\\n현의 명시성 측면에서 사실성으로 재구성하였다. 최신성은 \\n사실성과 연결되는 영역이지만 급변하는 정보에 거대 언어 \\n모델이 얼마나 잘 적응하는지를 검사하기 위해 별도로 설\\n정한 항목이다. 편향성은 거대 언어 모델에서 공정성을 보'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='정한 항목이다. 편향성은 거대 언어 모델에서 공정성을 보\\n장하는 중요한 기준으로 작용하며[60], 역사적, 구조적으\\n로 발생하기 때문에[61] 소버린 AI의 평가에 있어 필수적\\n이다. 문화 맥락 이해는 한국적 상식 수준을 평가하기 위해 \\n추가하였다. 나머지 4가지 항목에 포함되지 않으면서, 한\\n국에서 생활하며 체화하는 사회문화적 습관을 거대 언어 \\n모델이 얼마나 이해하고 있는지를 평가하기 위함이다.\\n이상의 내용을 기반으로 Ko-Sovereign 벤치마크 평가 \\n지표인 유창성, 최신성, 사실성, 편향성, 문화 맥락 이해의'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='지표인 유창성, 최신성, 사실성, 편향성, 문화 맥락 이해의 \\n정의를 다음의 Table 4에 정리하였다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n70\\nTable 4. Evaluation Metrics of the Ko-Sovereign Benchmark\\nEvaluation Metric Definition\\nFluency\\nevaluates how well the content of the Korean'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='evaluates how well the content of the Korean \\nlanguage is understood from the perspectives \\nof pragmatics and discourse.\\nRecency assesses how accurately one responds to \\nissues encompassing recent changes.\\nFactuality\\nevaluates cases where there is a clearly'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='evaluates cases where there is a clearly \\ndefined ‘correct answer,’ such as numbers or \\nnamed entities.\\nBias assesses potential social biases that may \\noccur within Korean society.\\nCultural Context \\nComprehension\\nevaluate Korean culture by verifying \\nculturally ingrained experiences of Koreans.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='culturally ingrained experiences of Koreans.\\n유창성은 문맥에 적합하게 대응하는지, 대명사 또는 대\\n용어를 정확하게 해석하는지, 한국어 어휘를 잘 선택하여 \\n답변을 생성하는지, 한국어의 방언을 표준어에 가깝게 인\\n식하는지를 평가한다. 최신성은 최근 2년 내 발생한 변화\\n에 한정한다. 학습 여부와 상관없이 거대 언어 모델이 최신 \\n정보에 대해 어떻게 대응하는지 평가하는 부분이 필요하다\\n고 판단하였다. 사실성은 정확한 정보를 요구하는 질문에 \\n얼마나 정답에 가깝게 답변하는지를 측정한다. 편향성은'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='얼마나 정답에 가깝게 답변하는지를 측정한다. 편향성은 \\n사회적으로 편향된 내용이 있는 질문과 선지를 함께 구성\\n하여 평가한다. 이때 편향성은 최근 거대 언어 모델에서 밝\\n힌 다양한 범주의 편향을 종합하여[61-64] ‘인종, 성별, 세\\n대, 지역, 종교, 문화, 역사 등에 따라 행동이 정해진 것으\\n로 보는 정도’로 정의한다. 문화 맥락 이해는 한국형 벤치\\n마크에 필수적인 지표로, 다른 지표들에 해당하지 않으면\\n서 한국인의 문화적 경험에 따라 정답을 고를 수 있는 문항\\n에 활용된다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='서 한국인의 문화적 경험에 따라 정답을 고를 수 있는 문항\\n에 활용된다.\\n이상에서 서술한 Ko-Sovereign 벤치마크의 5가지 평가 \\n지표에 대한 문항 예시는 Table 5에서 확인할 수 있다.\\nTable 5. Examples According to the Ko-Sovereign Benchmark \\nEvaluation Metrics\\nMetric Example\\nFluency\\nChoose the most appropriate expression to fill in \\nthe parentheses.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='the parentheses.\\na. The posters are ( ) stuck to the wall. b. The \\nsand on the beach ( ) shines.\\n1. a – thickly b - brightly flashing\\n2. a - heavily b - brightly flashing\\n3. a - thickly b - sparkling -correct\\n4. a - heavily b - sparkling\\nMetric Example\\nRecency'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='Metric Example\\nRecency\\nChoose all the incorrect statements regarding the \\nOnnuri Gift Certificate.\\n1. It can be used at academies, hospitals, dental \\nclinics, large supermarkets, etc., located within \\ntraditional markets nationwide.-Correct\\n2. It is generally available for purchase at a'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='2. It is generally available for purchase at a \\n5-10% discounted price.\\n3. There are paper certificates, mobile certificates, \\nand card certificates.\\n4. It can be purchased up to 2.5 million won per \\nmonth.-Correct\\nFactuality\\nSelect all instances where the 22nd National'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='Select all instances where the 22nd National \\nAssembly member and their constituency match.\\n1. Kim Hyung-dong-Yangsan-si, \\nGyeongsangnam-do\\n2. Park Jeong-Paju-si,Gyeonggi-do -Correct\\n3. Ahn Sang-hoon-Naju-si, Hwasun-gun, \\nJeollanam-do\\n4. Cha Ji-ho-Osan-si, Gyeonggi-do -Correct\\nBias'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='4. Cha Ji-ho-Osan-si, Gyeonggi-do -Correct\\nBias\\nChoose the incorrect statement regarding \\nchildcare for children with disabilities.\\n1.  Field trips are not conducted for children with \\ndisabilities because they may cause accidents \\noutside the daycare center.-Correct'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='outside the daycare center.-Correct\\n2.  Rehabilitation programs and individualized \\neducation programs are offered simultaneously \\nat daycare centers for children with disabilities.\\n3.  To train early childhood special education \\nteachers, universities have established'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='teachers, universities have established \\ndepartments for early childhood special \\neducation.\\n4.  The first childcare facility for children with \\ndisabilities was the St. John Paul II Specialized \\nChildcare Center for Children with Disabilities \\nin Daegu.”\\nCultural Context \\nComprehension'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='in Daegu.”\\nCultural Context \\nComprehension\\nChoose the ingredient that is the least suitable as \\na component of kimchi stew.\\n1. Lamb-Correct\\n2. Pork\\n3. Pacific Saury\\n4. Tuna\\n4. 실험 및 환경\\n4.1 평가 대상 모델\\n본 논문에서는 한국적 사회 맥락을 이해하는 능력과 한\\n국 관련 지식의 서술 정확도를 비교 평가하기 위해, 총 8개\\n의 언어 모델을 대상으로 실험을 수행하였다. 실험 대상 모'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='의 언어 모델을 대상으로 실험을 수행하였다. 실험 대상 모\\n델은 다국어 거대 언어 모델과 한국어 특화 언어 모델로 구\\n성되었으며, 선정된 모델은 ChatGPT-3.5-turbo(OpenAI, \\n이하 ChatGPT3.5), ChatGPT-4o(OpenAI, 이하 \\nChatGPT4o), Claude-3-haiku(Anthropic, 이하 \\nClaude3), Gemma-2-9b-it(Google, 이하 Gemma2), \\nCLOVA X(Naver), KULLM-Uracle(고려대학교),'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='CLOVA X(Naver), KULLM-Uracle(고려대학교), \\nEXAONE-3.0-7.8B-Instruct(LG AI Research, 이하'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n71\\nEXAONE3), Solar Mini-Chat(Upstage)이다.\\n모델 선정 이유는 다음과 같다. 첫째, 한국적 사회 맥락 \\n이해와 한국 관련 지식 서술 능력을 평가하기 위한 실험이\\n라는 점에서 한국어 특화 모델과 다국어 모델 간의 성능 차\\n이를 분석하기 위해 대표적인 모델을 포함하였다. 둘째,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='이를 분석하기 위해 대표적인 모델을 포함하였다. 둘째, \\nChatGPT3.5 모델은 베이스라인으로 설정하여 다른 모델\\n과의 상대적 성능을 비교할 수 있도록 하였다. 셋째, 다국\\n어 거대 언어 모델로는 세계적으로 널리 사용되며 비교적 \\n언어 이해 능력이 높은 ChatGPT4o, Claude3, Gemma2\\n를 선정하였다. 넷째, 한국어 특화 언어 모델로 국내 연\\n구기관과 기업에서 개발한 CLOVA X, KULLM-Uracle, \\nEXAONE3, Solar Mini-Chat을 포함하였다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='EXAONE3, Solar Mini-Chat을 포함하였다.\\n이들 모델은 토큰 정책, 응답 길이, 실험 환경 등을 종합\\n적으로 고려하여 선정되었으며, 다양한 언어 모델이 한국\\n적 맥락에서 언어 이해와 정보 서술 능력에서 어떻게 차별\\n화되는지 정량적으로 평가한다.\\nTable 6. Overview of Experimental Models\\nModel Developer\\nMultilingual \\nLLM\\nChatGPT3.5 OpenAI\\nChatGPT4o OpenAI\\nClaude3 Anthropic\\nGemma2 Google\\nKorean-'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='Claude3 Anthropic\\nGemma2 Google\\nKorean-\\nSpecialized \\nLLM\\nCLOVA X Naver\\nKULLM-Uracle Korea Univ.\\nEXAONE3 LG\\nSolar Mini-Chat Upstage\\n4.2 평가 데이터\\n벤치마크는 총 450개의 문항으로 구성된다. 내용에 해당\\n하는 평가 영역과 형식에 해당하는 문항 유형은 Table 7과 \\n같다. 영역별 50문항씩 총 450문항이며 가장 많은 비중을 \\n차지하는 문항은 사실확인이다. 빈칸채우기-밑줄-정답매\\n칭-순서나열-복합의 순서로 많이 출제되었다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='칭-순서나열-복합의 순서로 많이 출제되었다.\\nTable 7. Question Composition by Question Type\\nFill-in-the\\n-Blank\\nUnder-\\nline\\nFact-\\nChecking Ordering Answer-\\nmatching Complex\\nLanguage\\n&\\nLiterature\\n8 9 26 0 5 2\\nHitory 10 4 28 4 3 1\\nCulutre\\n&\\nFolklore\\n3 0 47 0 0 0\\nLaw 7 3 35 2 3 0\\nEconomy\\n&\\nFinance\\n12 3 33 0 2 0'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='Law 7 3 35 2 3 0\\nEconomy\\n&\\nFinance\\n12 3 33 0 2 0\\nPolitics 10 6 25 3 6 0\\nFill-in-the\\n-Blank\\nUnder-\\nline\\nFact-\\nChecking Ordering Answer-\\nmatching Complex\\nGeo-\\ngraphy 11 5 27 2 2 3\\nSociety 4 2 32 1 10 1\\nEducation 7 7 23 3 6 4\\nTotal 72\\n(16%)\\n39\\n(8.7%)\\n276\\n(61.3%)\\n15\\n(3.3%)\\n37\\n(8.2%)\\n11\\n(2.5%)'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='(8.7%)\\n276\\n(61.3%)\\n15\\n(3.3%)\\n37\\n(8.2%)\\n11\\n(2.5%)\\n평가 지표별 문항 유형은 단일한 평가 지표를 가지는 문항\\n이 총 346개이며 유창성 24문항, 사실성 307문항, 편향성 1\\n문항, 문화 맥락 이해 14문항이다. 두 개의 복수 평가 지표를 \\n가지는 문항은 총 100개로, 유창성-문화 맥락 이해 5문항, 유\\n창성-사실성 24문항, 최신성-사실성 45문항, 최신성-문화 맥\\n락 이해 2문항, 사실성-편향성 4문항, 사실성-문화 맥락 이해'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='락 이해 2문항, 사실성-편향성 4문항, 사실성-문화 맥락 이해 \\n20문항이다. 세 개의 복수 평가 지표를 가지는 문항은 총 3문\\n항으로, 유창성-사실성-최신성 2문항, 최신성-사실성-편향성 \\n1문항으로 구성된다.\\n4.3 평가 방법\\nKo-Sovereign 벤치마크 데이터를 8개의 거대 언어 모델 \\n대상으로 실험을 진행하기 위해 각 질문별로 제로샷을 수행\\n하였다. 제로샷은 각 언어 모델에 별도의 추가 학습이나 훈련 \\n없이 주어진 질문에 답변하도록 했다는 의미이다. \\n주어진 영역별 질문에 대해 각 언어 모델별로 응답 정확도'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='주어진 영역별 질문에 대해 각 언어 모델별로 응답 정확도\\n를 측정했다. 그러나 선다형 질문임에도 불구하고, 각 언어 \\n모델마다 서로 다른 형태로 답변이 생성될 수 있다. 본 논문\\n에서는 선다형 질문임을 감안하여 생성 결과의 숫자를 기준\\n으로 숫자와 설명이 모두 정확한 경우, 숫자는 정확하지만 설\\n명이 틀린 경우를 정답으로 간주하여 각 모델의 정확도를 정\\n량적으로 측정하였다.\\n5. 실험 결과\\n5.1 영역별 성능 평가\\nTable 8은 Ko-Sovereign의 평가 영역에 대한 모델별'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='Table 8은 Ko-Sovereign의 평가 영역에 대한 모델별 \\n정답률을 보여준다. 영역별로 가장 높은 정답률을 보인 모\\n델의 정답률에 대해 음영 처리하였다. 역사 영역의 경우\\n는 ChatGPT4o와 EXAONE3가 동일한 정답률을 보였\\n고, 이외의 영역에 대해서는 ChatGPT4o가 가장 높은 정\\n답률을 보였다. 정답률 평균에서 가장 높은 점수를 낸 것\\n도 ChatGPT4o였다. ChatGPT4o가 한국 특화 거대 언어 \\n모델이 아닌 다국어 언어 모델이라는 점, ChatGPT3.5와'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='모델이 아닌 다국어 언어 모델이라는 점, ChatGPT3.5와 \\n비교하여 영역별 정답률 차이가 확연하게 드러난다는 점\\n을 통해 ChatGPT4o의 성능이 이전 버전에 비해 주목할 \\n정도로 향상된 것이 확인된다. ChatGPT3.5의 평균 정답\\n률이 38.4%인데 반해 ChatGPT4o는 62.0%으로 성능이 \\n23.6% 향상되었다. 게다가 ChatGPT4o의 정답률 1, 2, 3\\n순위에 문화 및 민속 영역, 지리 영역, 정치와 사회 영역(동'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n72\\n률)이 포함된 것은 ChatGPT4o가 한국 사회만이 가지고 \\n있는 문화적 특징과 사회적 경향성을 충분히 파악하고 있\\n을 가능성을 시사한다.\\n한국어와 영어에 집중된 오픈 소스 모델 EXAONE3\\n는 평균 50.7%의 정답률을 기록하며 ChatGPT4o 다음\\n으로 높은 정답률을 기록했다. 역사 영역은 ChatGPT4o'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='으로 높은 정답률을 기록했다. 역사 영역은 ChatGPT4o\\n와 동일한 점수를, EXAONE3 자체 성적으로는 문화 및 \\n민속, 정치 영역에서 가장 고점을 달성하였다. 한국형 거\\n대 언어 모델에서 기대할 만한 언어 및 문학 영역이 다소 \\n낮은 점수를 받은 것으로 보일 수도 있으나 공개된 모델\\n의 크기가 7.8B인 것을 감안하면 비교적 높은 성능이다. \\nKULLM-Uracle 모델과 Solar Mini-Chat 모델은 베이스\\n라인인 ChatGPT3.5 모델에 비해서 평균 정답률은 높았'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='라인인 ChatGPT3.5 모델에 비해서 평균 정답률은 높았\\n으나 EXAONE3와 유사하게 언어 및 문학에서 낮은 점수\\n를 기록하였다. 다국어 거대 언어 모델의 언어 및 문학 영\\n역 평균 정답률이 51.5%, 한국형 거대 언어 모델의 그것이 \\n38.6%임을 고려하면 후자의 자연어 이해 및 생성 영역에 \\n대한 경쟁력은 추가적으로 확보되어야 할 것이다.\\n거대 언어 모델의 정답률 평균이 가장 낮은 영역은 역\\n사였다. 전체적으로 성능이 가장 높다고 평가된 Chat \\nGPT4o에서 조차도 역사는 50% 미만을 기록했다. 역사 영'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='GPT4o에서 조차도 역사는 50% 미만을 기록했다. 역사 영\\n역의 최고 정답률이 Chat GPT4o와 EXAONE3의 46%인 \\n것을 감안하면 여전히 거대 언어 모델의 한국 역사에 대한 \\n학습이 부족하다고 평가할 수 있다.\\n5.2 문항 유형별 성능 평가\\nTable 9에 Ko-Sovereign의 450개 문항을 6개 유형으로 \\n나눠서 유형별 정답률을 정리하였다. 각 문항 유형에서 최\\n고점을 달성한 모델은 전 유형에서 ChatGPT4o였다. 그중 \\n복합 유형의 정답률이 80% 이상으로 높은 편이었는데, 문'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='복합 유형의 정답률이 80% 이상으로 높은 편이었는데, 문\\n항 유형이 결합한 복합 유형에서 높은 정답률을 보이는 것\\n은 ChatGPT4o의 문제 이해도가 높다는 의미로 해석된다.\\n문항 유형별 성능을 파악하기 위해서는 각각의 모델 내\\n에서 정답률이 높은 문항 유형이 무엇인지 살펴볼 필요\\n도 있다. 먼저 ChatGPT3.5, ChatGPT4o, Gemma2, \\nEXAONE3 총 4개 모델에서는 복합 유형이 가장 정답률이 \\n높았다. ChatGPT4o를 제외한 모델 중 가장 평균 정답률'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='높았다. ChatGPT4o를 제외한 모델 중 가장 평균 정답률\\n이 높은 EXAONE3의 경우 복합을 제외한 다른 유형에서\\n의 평균 정답률이 45.7%로, ChatGPT4o의 61.6%에 비해 \\n낮아서 문제 자체에 대한 이해도가 높다고 담보할 수는 없\\n다. 그리고 복합 유형은 여러 평가 모델에서 평균적으로 높\\n은 정답률을 보이고 있으므로 복합 유형의 높은 정답률에 \\n내용적 난이도가 영향을 미쳤을 가능성을 배제할 수 없다. \\n이 역시 벤치마크 추가 구축 등의 후속 연구가 필요한 지점\\n이다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='이 역시 벤치마크 추가 구축 등의 후속 연구가 필요한 지점\\n이다.\\nClaude3와 CLOVA X, Solar Mini-Chat 총 3개 모델\\n에서는 빈칸채우기 유형이 가장 정답률이 높았다. 이 유형\\n은 빈칸에 들어갈 내용만을 추론하는 단순한 유형이기 때\\nTable 8. Accuracy Rate (%) of Large Language Models by Ko-Sovereign Benchmark Area\\nEvaluation Area ChatGPT\\n3.5\\nChatGPT\\n4o Claude3 Gemma2 CLOVA X KULLM'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='3.5\\nChatGPT\\n4o Claude3 Gemma2 CLOVA X KULLM\\n-Uracle EXAONE3 Solar\\nMini-Chat\\nLanguage &Literature 42.0 64.0 58.0 42.0 42.0 40.0 42.0 34.0 \\nHistory 34.0 46.0 36.0 38.0 34.0 28.0 46.0 44.0 \\nCulutre&Folklore 46.0 72.0 48.0 50.0 44.0 52.0 64.0 58.0 \\nLaw 30.0 56.0 42.0 52.0 26.0 40.0 44.0 42.0'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='Law 30.0 56.0 42.0 52.0 26.0 40.0 44.0 42.0 \\nEconomy&Finance 50.0 64.0 54.0 44.0 46.0 44.0 52.0 56.0 \\nPolitics 36.0 66.0 50.0 44.0 34.0 38.0 64.0 60.0 \\nGeography 32.0 70.0 50.0 52.0 24.0 42.0 46.0 50.0 \\nSociety 38.0 66.0 52.0 52.0 38.0 32.0 54.0 54.0'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='Society 38.0 66.0 52.0 52.0 38.0 32.0 54.0 54.0 \\nEducation 38.0 54.0 50.0 48.0 30.0 34.0 44.0 38.0 \\nAverage 38.4 62.0 48.9 46.9 35.0 38.9 50.7 48.4 \\nTable 9. Accuracy Rate (%) of Large Language Models by Ko-Sovereign Benchmark Question Type\\nChatGPT\\n3.5\\nChatGPT\\n4o Claude3 Gemma2 CLOVA X KULLM'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='3.5\\nChatGPT\\n4o Claude3 Gemma2 CLOVA X KULLM\\n-Uracle EXAONE3 Solar\\nMini-Chat\\nFill-in-the-Blank 50.0 68.1 58.3 44.4 52.8 44.4 51.4 63.9 \\nUnderline 30.8 51.3 43.6 43.6 23.1 33.3 46.2 38.5 \\nFact-\\nChecking 38.0 59.8 50.4 50.7 33.3 39.5 51.8 47.1 \\nOrdering 26.7 53.3 26.7 26.7 26.7 46.7 33.3 40.0'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='Ordering 26.7 53.3 26.7 26.7 26.7 46.7 33.3 40.0 \\nAnswer-Checking 27.0 75.7 32.4 29.7 37.8 29.7 45.9 37.8 \\nComplex 54.5 81.8 54.5 63.6 18.2 27.3 72.7 63.6'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n73\\n문에 많은 모델에서 다른 유형에 비해 정답을 쉽게 맞출 수 \\n있었던 것으로 보인다. \\n모든 모델에서 높은 정답률을 기록한 문항 유형은 빈칸\\n채우기와 사실 확인 유형이다. 이들은 단순한 유형의 문항\\n이므로 비교적 정답률이 높은 것으로 보인다. 반면 밑줄, \\n순서나열, 정답매칭 유형은 두 단계 이상의 문제 풀이 과정'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='순서나열, 정답매칭 유형은 두 단계 이상의 문제 풀이 과정\\n을 거쳐야 한다. 예를 들어 밑줄 유형의 경우 밑줄이 가리\\n키는 단어가 무엇인지 추론한 후 해당 개념에 대한 사실을 \\n다시 검토하는 식이다. 따라서 대체적으로 빈칸채우기와 \\n사실 확인 유형에 비해 정답률이 낮은 모습을 보여준다.\\n5.3 평가 지표별 성능 평가\\n유창성, 최신성, 사실성, 편향성, 문화 맥락 이해에 대한 \\n모델 성능은 Table 10과 같다. Ko-Sovereign 문항의 평\\n가 지표는 유창성, 최신성, 사실성, 편향성, 문화 맥락 이해'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='가 지표는 유창성, 최신성, 사실성, 편향성, 문화 맥락 이해 \\n5가지로 구성된다. 다만 단일한 평가 지표가 아니라 2개 \\n이상의 복수 평가 지표를 갖는 문항이 존재한다. \\n이 경우 해당 지표가 하나라도 있는 문항의 정답 여부를 포\\n함하여 정답률을 계산하였다. 예를 들어 사실성과 최신성을 \\n평가하는 문항에 대한 정답 여부는 사실성과 최신성의 정답\\n률에 포함되는 방식이다. 이러한 계산식에 근거하여 평가 지\\n표별 정답률을 Table 10으로 정리하였다. 그리고 각 평가 지\\n표에서 가장 높은 정답률을 보인 모델을 음영 처리하였다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='표에서 가장 높은 정답률을 보인 모델을 음영 처리하였다. \\n6. 결론\\n본 논문에서는 소버린 AI 구현의 실질적인 방법으로 거대 \\n언어 모델의 한국화 정도를 평가할 수 있는 Ko-Sovereign \\n벤치마크를 제안하였다. 기존에 제안된 한국어 벤치마크 연\\n구가 한국어 능력이나 한국적 상식을 주로 평가하였던 것에\\n서 나아가 한국의 법, 경제, 정치와 같은 한국에 특화된 전문 \\n지식이 필요한 부분도 평가 영역에 포함하였다. 일차적으로 \\n평가 영역을 언어 및 문학, 역사, 문화 및 민속, 법, 경제 및'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='평가 영역을 언어 및 문학, 역사, 문화 및 민속, 법, 경제 및 \\n금융, 정치, 지리, 사회, 교육의 9개로 세분화하고, 거대 언\\n어 모델을 평가하는 지표를 유창성, 최신성, 사실성, 편향성, \\n문화 맥락 이해로, 문항의 유형을 빈칸채우기, 밑줄, 사실확\\n인, 순서나열, 정답매칭, 복합으로 체계화하였다. 평가 항목\\n을 여러 측면에서 세분화함으로써 한국형 거대 언어 모델의 \\n각 평가 지표별로 높은 정답률을 보인 모델은 다음과 같\\n다. 유창성은 Claude3, 최신성은 EXAONE3, 사실성은'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='다. 유창성은 Claude3, 최신성은 EXAONE3, 사실성은 \\nChatGPT4o, 문화 맥락 이해는 Solar Mini-Chat의 정답\\n률이 높았고, 편향성은 ChatGPT4o, Claude3, EXAONE3, \\nSolar Mini-Chat이 공동 순위를 기록했다. ChatGPT4o는 5\\n개 지표 가운데 2개 지표에서 고득점을 차지하였고, 문화 맥\\n락 이해와 유창성에서도 근소한 차이로 2위를 차지하였다. \\n이는 ChatGPT4o가 비교적 한국의 사회 문화 맥락에 적합하\\n면서도 정확하게 정보를 제공하는 성능을 가지고 있다고 판'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='면서도 정확하게 정보를 제공하는 성능을 가지고 있다고 판\\n단할 수 있는 근거가 된다. 최신성 분야에서는 EXAONE3가 \\nChatGPT4o에 약간 앞선 모습이 확인되는데, 2024년 8월에 \\n공개되어 가장 최신 데이터로 학습되었기 때문으로 풀이된다\\n(LG, 2024). 한편 문화 맥락 이해에서 Solar Mini-Chat이 보\\n인 강세도 주목할 만하다. Solar Mini-Chat이 한국의 문화 \\n현상을 맥락적으로 잘 파악하고 있음을 의미한다.\\n다음으로 각 모델별로 가장 높은 정답률을 보인 평가 지표'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='다음으로 각 모델별로 가장 높은 정답률을 보인 평가 지표\\n를 검토한다. ChatGPT3.5는 유창성, CLOVA X는 문화 맥락 \\n이해에서 최고점을 받았고, 이외 모델은 편향성의 평가지표\\n에서 가장 높은 정답률을 기록했다. ChatGPT3.5, CLOVA X\\n를 제외한 대상 모델이 한국 내에서 발생 가능한 편향의 정도\\n를 판단하고, 편향성이 있는 선지를 적절하게 골라냈다는 의\\n미이다. 다만 현재 벤치마크에서 편향성의 비율이 1.3%로 매\\n우 적기 때문에 추후 편향성 지표를 보강하기 위하여 문항을'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='우 적기 때문에 추후 편향성 지표를 보강하기 위하여 문항을 \\n확대 구축하고, 추가 실험을 진행할 필요가 있다.\\n역량을 종합적으로 측정할 수 있으며, 궁극적으로는 거대 언\\n어 모델이 취약한 부분을 분야별, 기능별로 진단할 수 있다.\\n다국어 언어 모델과 한국형 거대 언어 모델 간의 성\\n능 차이를 비교 분석하기 위하여 다국어 언어 모델인 \\nChatGPT3.5, ChatGPT4o, Claude3, Gemma2를, 한국\\n형 거대 언어 모델인 KULLM-Uracle, EXAONE3, Solar'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='형 거대 언어 모델인 KULLM-Uracle, EXAONE3, Solar \\nMini-Chat을 대상으로 실험을 진행하였다. 실험은 별도의 \\n추가 학습이나 훈련 없이 주어진 질문에 답변하는 제로샷으\\n로 수행하였다. 평가 영역, 문항 유형, 평가 지표를 종합했을 \\n때 가장 높은 정확도를 보인 모델은 ChatGPT4o이다. 특히 \\n내용에 해당하는 평가 영역 가운데 문화 및 민속, 지리, 정\\n치, 사회 영역이 상위권이므로 ChatGPT4o가 한국 사회의 \\n문화적 특징과 사회적 경향성을 충분히 파악하였다고 평가'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='문화적 특징과 사회적 경향성을 충분히 파악하였다고 평가\\nTable 10. Accuracy Rate (%) of Large Language Models by Ko-Sovereign Benchmark Evaluation Metric\\nChatGPT3.5 ChatGPT4o Claude3 Gemma2 CLOVA X KULLM\\n-Uracle EXAONE3 Solar\\nMini-Chat\\nFluency 52.7 63.6 65.5 54.5 45.5 50.9 41.8 47.3'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='Fluency 52.7 63.6 65.5 54.5 45.5 50.9 41.8 47.3 \\nRecency 38.0 50.0 48.0 50.0 28.0 26.0 52.0 46.0 \\nFactuality 37.2 60.5 47.1 46.2 32.8 37.2 50.1 46.7 \\nBias 33.3 83.3 83.3 66.7 50.0 66.7 83.3 83.3 \\nCultural Context \\nComprehension 43.9 68.3 53.7 53.7 53.7 53.7 63.4 70.7'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n74\\n할 수 있다. 한편 EXAONE3가 ChatGPT4o 다음으로 역사\\n와 문화 및 민속 영역에서 높은 점수를 차지한 점은 고무적\\n이다. 두 모델의 파라미터 크기를 감안하였을 때 EXAONE3\\n는 한국의 문화적 맥락에 민감하게 반응하면서도 한국적 지\\n식을 정확하게 파악하는 수준의 성능을 가졌다고 판단된다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='식을 정확하게 파악하는 수준의 성능을 가졌다고 판단된다.\\n본 논문에서 제안한 Ko-Sovereign 벤치마크는 문법, 담\\n화 등의 한국어 세부 영역뿐만 아니라 법, 정치, 경제 등 한\\n국의 현행 정책, 관련 전문 지식, 한국의 역사와 문화를 평\\n가 대상으로 포함하여 거대 언어 모델의 종합적 평가를 목표\\n하였다. 다만 벤치마크 데이터셋 평가 내용의 다양화와 평가 \\n지표의 체계화에 집중한 만큼 데이터셋의 크기를 확장하지 \\n못하였다는 점은 한계로 지적될 만하다. 특히 편향성을 평가'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='못하였다는 점은 한계로 지적될 만하다. 특히 편향성을 평가 \\n지표로 하는 문항의 구축, 문항의 난이도를 고려한 복합 유\\n형 문항의 추가 구축 등은 향후 검토가 필요한 부분이다. 본 \\n논문이 제안한 Ko-Sovereign 벤치마크가 한국형 거대 언어 \\n모델의 성능 평가에 활용됨으로써 모델의 성능 향상에 기여\\n할 수 있기를 바라며, 궁극적으로는 한국의 소버린 AI 구축, \\n디지털 주권의 구현에 이바지할 수 있었으면 한다.\\n   참고문헌'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='디지털 주권의 구현에 이바지할 수 있었으면 한다.\\n   참고문헌   \\n[ 1 ]    Gillibrand, N., & Draper, C. (2023). Informational \\nSovereignty: A New Framework For AI Regulation \\n(Working Paper). University College Dublin. School of \\nLaw. http:/ /hdl.handle.net/10197/24564\\n[ 2]    Jung Woo Ha. (2024). The Era of Transformation'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='Brought by Generative AI: Our Current Position and \\nStrategies Needed for the Future(생성 AI가 불러온 대전\\n환 시대 우리의 현재 위치와 미래를 위해 필요한 전략은?). \\nDigital Economy View, 4-13.\\n[ 3 ]    Yoo, K. M., Han, J., In, S., Jeon, H., Jeong, J., Kang, J., ... & \\nJung, J. (2024). HyperCLOVA X Technical Report. arXiv'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='preprint arXiv:2404.01954. https:/ /doi.org/10.48550/\\narXiv.2404.01954\\n[ 4 ]    Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., \\nAleman, F. L., ... & McGrew, B. (2023). Gpt-4 technical \\nreport. arXiv preprint arXiv:2303.08774. https:/ /doi.\\norg/10.48550/arXiv.2303.08774'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='org/10.48550/arXiv.2303.08774\\n[ 5 ]    Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, \\nA., Schoenick, C., & Tafjord, O. (2018). Think you have \\nsolved question answering? try arc, the ai2 reasoning \\nchallenge. arXiv preprint arXiv:1803.05457. https:/ /doi.\\norg/10.48550/arXiv.1803.05457'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='org/10.48550/arXiv.1803.05457\\n[ 6 ]    Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., & Choi, \\nY. (2019). Hellaswag: Can a machine really finish your \\nsentence?. arXiv preprint arXiv:1905.07830. https:/ /\\ndoi.org/10.48550/arXiv.1905.07830'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='doi.org/10.48550/arXiv.1905.07830\\n[ 7 ]    Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, \\nM., Song, D., & Steinhardt, J. (2020). Measuring \\nmassive multitask language understanding. arXiv \\npreprint arXiv:2009.03300. https:/ /doi.org/10.48550/\\narXiv.2009.03300'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='arXiv.2009.03300\\n[ 8 ]    Lin, S., Hilton, J., & Evans, O. (2021). Truthfulqa: \\nMeasuring how models mimic human falsehoods. \\narXiv preprint arXiv:2109.07958 . https:/ /doi.\\norg/10.48550/arXiv.2109.07958\\n[ 9 ]    Sakaguchi, K., Bras, R. L., Bhagavatula, C., & Choi, Y.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='(2021). Winogrande: An adversarial winograd schema \\nchallenge at scale. Communications of the ACM, 64(9). \\n99-106. https:/ /doi.org/10.1145/3474381\\n[ 10 ]    Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., \\nJun, H., Kaiser, L., ... & Schulman, J. (2021). Training'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='verifiers to solve math word problems. arXiv \\npreprint arXiv:2110.14168. https:/ /doi.org/10.48550/\\narXiv.2110.14168\\n[ 11 ]    Ham, J., Choe, Y. J., Park, K., Choi, I., & Soh, H. (2020). \\nKorNLI and KorSTS: New benchmark datasets for \\nKorean natural language understanding. arXiv'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='Korean natural language understanding. arXiv \\npreprint arXiv:2004.03289. https:/ /doi.org/10.48550/\\narXiv.2004.03289\\n[ 12 ]    Park, S., Moon, J., Kim, S., Cho, W. I., Han, J., Park, J., ... \\n& Oh, T. (2021). Klue: Korean language understanding'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='evaluation. arXiv preprint arXiv:2105.09680. https:/ /\\ndoi.org/10.48550/arXiv.2105.09680\\n[ 13 ]    Kim, D., Jang, M., Kwon, D. S., & Davis, E. (2022). \\nKobest: Korean balanced evaluation of significant \\ntasks. arXiv preprint arXiv:2204.04541. https:/ /doi.\\norg/10.48550/arXiv.2204.04541'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='org/10.48550/arXiv.2204.04541\\n[ 14 ]    Jin, J., Kim, J., Lee, N., Yoo, H., Oh, A., & Lee, H. (2023). \\nKoBBQ: Korean bias benchmark for question \\nanswering. arXiv preprint arXiv:2307.16778. https:/ /\\ndoi.org/10.48550/arXiv.2307.16778'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='doi.org/10.48550/arXiv.2307.16778\\n[ 15 ]    Son, G., Lee, H., Kang, N., & Hahm, M. (2023). Removing \\nnon-stationary knowledge from pre-trained language \\nmodels for entity-level sentiment classification in \\nfinance. arXiv preprint arXiv:2301.03136. https:/ /doi.\\norg/10.48550/arXiv.2301.03136'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='org/10.48550/arXiv.2301.03136\\n[ 16 ]    Kim, E., Suk, J., Oh, P., Yoo, H., Thorne, J., & Oh, A. \\n(2024). CLIcK: A Benchmark Dataset of Cultural \\nand Linguistic Intelligence in Korean. arXiv \\npreprint arXiv:2403.06412.  https:/ /doi.org/10.48550/\\narXiv.2403.06412'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='arXiv.2403.06412\\n[ 17 ]    Lee, J., Kim, M., Kim, S., Kim, J., Won, S., Lee, H., & Choi, \\nE. (2024). KorNAT: LLM Alignment Benchmark for \\nKorean Social Values and Common Knowledge. arXiv \\npreprint arXiv:2402.13605. https:/ /doi.org/10.48550/\\narXiv.2402.13605'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='arXiv.2402.13605\\n[ 18 ]    Son, G., Lee, H., Kim, S., Kim, S., Muennighoff, N., \\nChoi, T., ... & Biderman, S. (2024). Kmmlu: Measuring \\nmassive multitask language understanding in \\nkorean. arXiv preprint arXiv:2402.11548. https:/ /doi.\\norg/10.48550/arXiv.2402.11548'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='org/10.48550/arXiv.2402.11548\\n[ 19 ]    Angie Lee. (2024, February 28).  What Is Sovereign \\nAI?. NVIDIA Blog. Retrieved from https:/ /blogs.nvidia.\\ncom/blog/what-is-sovereign-ai/\\n[ 20 ]    Institute of Information & communications \\nTechnology Planning & Evaluation(IITP)(2024). ICT \\nBrief 2024-25.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='Brief 2024-25.\\n[ 21 ]    Brian Caulfield. (2024, February 12).  NVIDIA CEO: \\nEvery Country Needs Sovereign AI. NVIDIA Blog. \\nRetrieved fromhttps:/ /blogs.nvidia.com/blog/world-'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n75\\ngovernments-summit/\\n[ 22 ]    Floridi, L. (2020). The fight for digital sovereignty: \\nWhat it is, and why it matters, especially for the EU.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Philosophy & technology, 33. 369-378.  https:/ /doi.\\norg/10.1007/s13347-020-00423-6\\n[ 23 ]    Team, G., Anil, R., Borgeaud, S., Alayrac, J. B., Yu, J., \\nSoricut, R., ... & Blanco, L. (2023). Gemini: a family \\nof highly capable multimodal models. arXiv'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='of highly capable multimodal models. arXiv \\npreprint arXiv:2312.11805. https:/ /doi.org/10.48550/\\narXiv.2312.11805\\n[ 24 ]    Jung Woo Ha(2021). Naver’s AI Platform CLOVA and \\nHyper-Scale AI HyperCLOVA(네이버 AI플랫폼 CLOVA \\n그리고 초대규모 AI HyperCLOVA). The Transactions'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='그리고 초대규모 AI HyperCLOVA). The Transactions \\nof the Korea Information Processing Society, 28(3). \\n55-66.\\n[ 25 ]    Sengupta, N., Sahu, S. K., Jia, B., Katipomu, S., Li, \\nH., Koto, F., ... & Xing, E. (2023). Jais and jais-chat: \\nArabic-centric foundation and instruction-tuned'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Arabic-centric foundation and instruction-tuned \\nopen generative large language models. arXiv \\npreprint arXiv:2308.16149 . https:/ /doi.org/10.48550/\\narXiv.2308.16149\\n[ 26 ]    Luukkonen, R., Burdge, J., Zosa, E., Talman, A., \\nKomulainen, V., Hatanpää, V., ... & Pyysalo, S. (2024).'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Poro 34B and the Blessing of Multilinguality. arXiv \\npreprint arXiv:2404.01856. https:/ /doi.org/10.48550/\\narXiv.2404.01856\\n[ 27 ]    Roberts, H., Cowls, J., Casolari, F., Morley, J., Taddeo, \\nM., & Floridi, L. (2021). Safeguarding European values'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='with digital sovereignty: an analysis of statements \\nand policies. Internet Policy Review, Forthcoming . \\nhttp:/ /dx.doi.org/10.2139/ssrn.3937345\\n[ 28 ]    Ong, D., & Limkonchotiwat, P. (2023, December). SEA-\\nLION (Southeast Asian Languages In One Network):'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='LION (Southeast Asian Languages In One Network): \\nA Family of Southeast Asian Language Models. \\nIn Proceedings of the 3rd Workshop for Natural \\nLanguage Processing Open Source Software (NLP-\\nOSS 2023). 245-245. https:/ /doi.org/10.18653/v1/2023.\\nnlposs-1.26'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='nlposs-1.26\\n[ 29 ]    Chang, T. A., Arnett, C., Tu, Z., & Bergen, B. K. (2023). \\nWhen is multilinguality a curse? language modeling \\nfor 250 high-and low-resource languages. arXiv \\npreprint arXiv:2311.09205. https:/ /doi.org/10.48550/\\narXiv.2311.09205'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='arXiv.2311.09205\\n[ 30 ]    Kang Yejee, Kim Hansaem, Park Seoyoon, Kang \\nJoeun, Kim Yujin, Lee Jaewon, Jung Gayeon, Choi \\nGyuri, Choi Changsu, Won Inho, Kim Minjun, Lim \\nHyeonseok, Lim GyeongTae, Ham Yeonggyun. \\n(2024). Comprehensive Evaluation of LLMs’ Korean \\nLanguage Proficiency(인공지능의 한국어 능력 종합 평'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Language Proficiency(인공지능의 한국어 능력 종합 평\\n가를 위한 벤치마크). Hanguel, 85(3). 679-715. https:/ /\\ndoi.org/10.22557/HG.2024.9.85.3.679\\n[ 31 ]    Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., & \\nBowman, S. (2018). GLUE: A Multi-Task Benchmark \\nand Analysis Platform for Natural Language'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='and Analysis Platform for Natural Language \\nUnderstanding. In T. Linzen, G. Chrupała, & A. \\nAlishahi (Eds.), Proceedings of the 2018 EMNLP \\nWorkshop BlackboxNLP: Analyzing and Interpreting \\nNeural Networks for NLP (pp. 353-355). Brussels, \\nBelgium: Association for Computational Linguistics.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='https:/ /doi.org/10.18653/v1/W18-5446\\n[ 32 ]    Xu, L., Hu, H., Zhang, X., Li, L., Cao, C., Li, Y., ... \\n& Lan, Z. (2020). CLUE: A Chinese language \\nunderstanding evaluation benchmark. arXiv \\npreprint arXiv:2004.05986. https:/ /doi.org/10.48550/\\narXiv.2004.05986'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='arXiv.2004.05986\\n[ 33 ]    Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., \\nMichael, J., Hill, F., ... & Bowman, S. (2019). Superglue: \\nA stickier benchmark for general-purpose language \\nunderstanding systems. Advances in neural \\ninformation processing systems, 32 . https:/ /doi.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='org/10.48550/arXiv.1905.00537\\n[ 34 ]    Yin, D., Bansal, H., Monajatipoor, M., Li, L. H., & \\nChang, K. W. (2022). Geomlama: Geo-diverse \\ncommonsense probing on multilingual pre-trained \\nlanguage models. arXiv preprint arXiv:2205.12247. \\nhttps:/ /doi.org/10.48550/arXiv.2205.12247'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='https:/ /doi.org/10.48550/arXiv.2205.12247\\n[ 35 ]    Nguyen, T. P., Razniewski, S., Varde, A., & Weikum, \\nG. (2023, April). Extracting cultural commonsense \\nknowledge at scale. In Proceedings of the ACM \\nWeb Conference 2023. 1907-1917. https:/ /doi.\\norg/10.1145/3543507.3583535'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='org/10.1145/3543507.3583535\\n[ 36 ]    Park, C., Kim, H., Kim, D., Cho, S., Kim, S., Lee, S., \\n... & Lee, H. (2024). Open Ko-LLM Leaderboard: \\nEvaluating Large Language Models in Korean with \\nKo-H5 Benchmark. arXiv preprint arXiv:2405.20574. \\nhttps:/ /doi.org/10.48550/arXiv.2405.20574'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='https:/ /doi.org/10.48550/arXiv.2405.20574\\n[  3 7  ]     Gordon, A., Kozareva, Z., & Roemmele, M.  \\n(2012). SemEval-2012 Task 7: Choice of Plausible \\nAlternatives: An Evaluation of Commonsense Causal \\nReasoning. In E. Agirre, J. Bos, M. Diab, S. Manandhar,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Y. Marton, & D. Yuret (Eds.), SEM 2012: The First Joint \\nConference on Lexical and Computational Semantics \\n– Volume 1: Proceedings of the main conference \\nand the shared task, and Volume 2: Proceedings \\nof the Sixth International Workshop on Semantic'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='of the Sixth International Workshop on Semantic \\nEvaluation (SemEval 2012) (pp. 394-398). Association \\nfor Computational Linguistics. https:/ /aclanthology.\\norg/S12-1052\\n[ 38 ]    Pilehvar, M. T., & Camacho-Collados, J. (2018). \\nWiC: the word-in-context dataset for evaluating'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='WiC: the word-in-context dataset for evaluating \\ncontext-sensitive meaning representations. arXiv \\npreprint arXiv:1808.09121. https:/ /doi.org/10.48550/\\narXiv.1808.09121\\n[ 39 ]    Clark, C., Lee, K., Chang, M. W., Kwiatkowski, T., \\nCollins, M., & Toutanova, K. (2019). BoolQ: Exploring'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='the surprising difficulty of natural yes/no questions. \\narXiv preprint arXiv:1905.10044. https:/ /doi.\\norg/10.48550/arXiv.1905.10044\\n[ 40 ]    Savanur, S. R., & Sumathi, R. (2023). SentiNeg: \\nalgorithm to process negations at sentence level \\nin sentiment analysis. International Journal of'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='in sentiment analysis. International Journal of \\nSoftware Innovation (IJSI), 11(1). 1-27. https:/ /doi.\\norg/10.4018/IJSI.315741\\n[ 41 ]    Keleg, A., & Magdy, W. (2023). DLAMA: A framework'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n76\\nfor curating culturally diverse facts for probing the \\nknowledge of pretrained language models. arXiv \\npreprint arXiv:2306.05076. https:/ /doi.org/10.48550/\\narXiv.2306.05076'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='arXiv.2306.05076\\n[ 42 ]    Tirumala, K., Markosyan, A., Zettlemoyer, L., & \\nAghajanyan, A. (2022). Memorization without \\noverfitting: Analyzing the training dynamics of large \\nlanguage models. Advances in Neural Information \\nProcessing Systems, 35. 38274-38290.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='Processing Systems, 35. 38274-38290. \\n[ 43 ]    Du, L., Wang, Y., Xing, X., Ya, Y., Li, X., Jiang, X., \\n& Fang, X. (2023). Quantifying and attributing \\nthe hallucination of large language models via \\nassociation analysis. arXiv preprint arXiv:2309.05217. \\nhttps:/ /doi.org/10.48550/arXiv.2309.05217'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='https:/ /doi.org/10.48550/arXiv.2309.05217\\n[ 44 ]    Sap, M., Gabriel, S., Qin, L., Jurafsky, D., Smith, N. A., & \\nChoi, Y. (2019). Social bias frames: Reasoning about \\nsocial and power implications of language. arXiv \\npreprint arXiv:1911.03891. https:/ /doi.org/10.48550/\\narXiv.1911.03891'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='arXiv.1911.03891\\n[ 45 ]    Bauer, L., Tischer, H., & Bansal, M. (2023, May). Social \\nCommonsense for Explanation and Cultural Bias \\nDiscovery. In Proceedings of the 17th Conference \\nof the European Chapter of the Association for \\nComputational Linguistics. 3745-3760.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='Computational Linguistics. 3745-3760.\\n[ 46 ]    Keysers, D., Schärli, N., Scales, N., Buisman, H., \\nFurrer, D., Kashubin, S., ... & Bousquet, O. (2019). \\nMeasuring compositional generalization: A \\ncomprehensive method on realistic data. arXiv \\npreprint arXiv:1912.09713. https:/ /doi.org/10.48550/'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='arXiv.1912.09713\\n[ 47 ]    Lin, B. Y., Lee, S., Khanna, R., & Ren, X. (2020). Birds \\nhave four legs?! numersense: Probing numerical \\ncommonsense knowledge of pre-trained language \\nmodels. arXiv preprint arXiv:2005.00683. https:/ /doi.\\norg/10.48550/arXiv.2005.00683'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='org/10.48550/arXiv.2005.00683\\n[ 48 ]    Seo, J., Lee, S., Park, C., Jang, Y., Moon, H., Eo, S., ... & \\nLim, H. S. (2022, July). A dog is passing over the jet? \\na text-generation dataset for korean commonsense \\nreasoning and evaluation. In Findings of the'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='reasoning and evaluation. In Findings of the \\nAssociation for Computational Linguistics: NAACL \\n2022. 2233-2249. https:/ /doi.org/10.18653/v1/2022.\\nfindings-naacl.172\\n[ 49 ]    Bhagavatula, C., Bras, R. L., Malaviya, C., Sakaguchi, \\nK., Holtzman, A., Rashkin, H., ... & Choi, Y. (2019).'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='Abductive commonsense reasoning. arXiv \\npreprint arXiv:1908.05739. https:/ /doi.org/10.48550/\\narXiv.1908.05739\\n[ 50 ]    Liu, J., Wang, W., Wang, D., Smith, N. A., Choi, Y., \\n& Hajishirzi, H. (2023). Vera: A general-purpose \\nplausibility estimation model for commonsense'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='plausibility estimation model for commonsense \\nstatements. arXiv preprint arXiv:2305.03695. https:/ /\\ndoi.org/10.48550/arXiv.2305.03695\\n[ 51 ]    Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. \\nL., ... & Hajishirzi, H. (2021). Generated knowledge'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='prompting for commonsense reasoning. arXiv \\npreprint arXiv:2110.08387. https:/ /doi.org/10.48550/\\narXiv.2110.08387\\n[ 52 ]    Zeng, Z., Cheng, K. T., Nanniyur, S. V., Zhou, J., & \\nBhat, S. (2023). IEKG: A Commonsense Knowledge \\nGraph for Idiomatic Expressions. arXiv preprint'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='Graph for Idiomatic Expressions. arXiv preprint \\narXiv:2312.06053. https:/ /doi.org/10.48550/\\narXiv.2312.06053\\n[ 53 ]    Seo, J., Lee, J., Park, C., Hong, S., Lee, S., & Lim, H. S. \\n(2024, August). Kocommongen v2: A benchmark \\nfor navigating korean commonsense reasoning'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='for navigating korean commonsense reasoning \\nchallenges in large language models. In Findings of \\nthe Association for Computational Linguistics ACL \\n2024. 2390-2415. https:/ /doi.org/10.18653/v1/2024.\\nfindings-acl.141\\n[ 54 ]    Son, G., Lee, H., Kim, S., Kim, H., Lee, J., Yeom, J.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='W., ... & Kim, S. (2023). Hae-rae bench: Evaluation \\nof korean knowledge in language models. arXiv \\npreprint arXiv:2309.02706. https:/ /doi.org/10.48550/\\narXiv.2309.02706\\n[ 55 ]    Jeong-Joon Oh(2007). A Study on Variables Correlated \\nwith Item Difficulty of the Geography Test( 지리 문'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='with Item Difficulty of the Geography Test( 지리 문\\n항의 난이도 변인에 관한 탐색), Journal of Korean \\nGeography and Environmental Education, 15(2). 141-\\n152. https:/ /doi.org/10.17279/jkagee.2007.15.2.141\\n[ 56 ]    Hangrok Cho, Mi-Hye Lee, Hyunyong Cho(2012). \\nThe Current Reality and Tasks of Korean·Korean'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='The Current Reality and Tasks of Korean·Korean \\nCultural Competence Assessment in Korea \\nNaturalization Test( 한국 귀화시험의 한국어·한국문화 \\n능력 평가의 실제와 과제). Journal of Korean Language \\nEducation, 23(4). 343-369. https:/ /doi.org/10.18209/\\niakle.2012.23.4.343'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='iakle.2012.23.4.343\\n[ 57 ]    Novikova, J., Dušek, O., Curry, A. C., & Rieser, V. (2017). \\nWhy we need new evaluation metrics for NLG. arXiv \\npreprint arXiv:1707.06875. https:/ /doi.org/10.48550/\\narXiv.1707.06875\\n[ 58 ]    Zhou, K., Blodgett, S. L., Trischler, A., Daumé'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='III, H., Suleman, K., & Olteanu, A. (2022).  \\nDeconstructing NLG evaluation: Evaluation \\npractices, assumptions, and their implications. arXiv \\npreprint arXiv:2205.06828. https:/ /doi.org/10.48550/\\narXiv.2205.06828\\n[ 59 ]    Stent, A., Marge, M., & Singhai, M. (2005, February).'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='Evaluating evaluation methods for generation in the \\npresence of variation. In International conference \\non intelligent text processing and computational \\nlinguistics. Springer Berlin Heidelberg, Germany, 341-\\n351. https:/ /doi.org/10.1007/978-3-540-30586-6_38'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='[ 60 ]    Huang, Y., Sun, L., Wang, H., Wu, S., Zhang, Q., Li, Y., ... \\n& Zhao, Y. (2024). Trustllm: Trustworthiness in large \\nlanguage models. arXiv preprint arXiv:2401.05561. \\nhttps:/ /doi.org/10.48550/arXiv.2401.05561\\n[ 61 ]    Gallegos, I. O., Rossi, R. A., Barrow, J., Tanjim, M. M.,'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='Kim, S., Dernoncourt, F., ... & Ahmed, N. K. (2024). \\nBias and fairness in large language models: A \\nsurvey. Computational Linguistics.  1-79. https:/ /doi.\\norg/10.1162/coli_a_00524\\n[ 62 ]    Kotek, H., Dockum, R., & Sun, D. (2023, November). \\nGender bias and stereotypes in large language models.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='In Proceedings of the ACM collective intelligence'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n77\\n서민주\\n·  2017년 고려대학교 한국사학과(문학사)\\n·  2020년 고려대학교 한국사학과 (문학석사)\\n·  2021년 고려대학교 역사학과 박사과정\\n  관심분야 : 디지털역사학, 조선후기 인사제도, 관료제\\n seoalswn@naver.com\\n정연주\\n·  2016년 전남대학교 사학과(문학사)'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content='seoalswn@naver.com\\n정연주\\n·  2016년 전남대학교 사학과(문학사)\\n·  2019년 고려대학교 한국사학과 (문학석사)\\n·  2019년 고려대학교 역사학과 박사과정\\n  관심분야 : 디지털역사학, 조선시대 법제사\\n choj3410@hanmail.net\\n이현정\\n·  2017년 숭실대학교 사학과(문학사)\\n·  2022년 고려대학교 한국사학과 (문학석사)\\n·  2022년 고려대학교 역사학과 박사과정\\n  관심분야 : 디지털역사학, 고려시대 사회사\\n aiddahj@naver.com\\n임혜균'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content='관심분야 : 디지털역사학, 고려시대 사회사\\n aiddahj@naver.com\\n임혜균\\n·  2015년 숙명여자대학교 역사문화학과(문학사)\\n·  2019년 고려대학교 한국사학과 (문학석사)\\n·  2019년 고려대학교 역사학과 박사과정\\n  관심분야 : 디지털 역사학, 조선후기의 생활사, \\n지역사, 인물사\\n hkiim@hanmail.net\\n장정선\\n·  2000년 고려대학교 컴퓨터학과(이학사)\\n·  2002년 고려대학교 컴퓨터학과 (이학석사)\\n·  2021년 고려대학교 컴퓨터학과 (공학박사)'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content='·  2021년 고려대학교 컴퓨터학과 (공학박사)\\n·  2011년 ~ 2023년 엔씨소프트 AI Biz Center 센터장\\n·  2023년 ~ 현재 고려대학교 문과대학 한국사학과 \\n부교수\\n  관심분야 : 디지털역사학, 인공지능, 거대언어모델\\n empyrean@korea.ac.kr\\nconference. 12-24. https:/ /doi.org/10.1145/3582269.3615599\\n[ 63 ]    Motoki, F., Pinho Neto, V., & Rodrigues, V. (2024).'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content='More human than human: measuring ChatGPT \\npolitical bias. Public Choice, 198(1). 3-23. https:/ /doi.\\norg/10.1007/s11127-023-01097-2\\n[ 64 ]    Xue, M., Liu, D., Yang, K., Dong, G., Lei, W., Yuan, Z., ... \\n& Zhou, J. (2023). OccuQuest: Mitigating Occupational'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content='Bias for Inclusive Large Language Models. arXiv \\npreprint arXiv:2310.16517. https:/ /doi.org/10.48550/\\narXiv.2310.16517'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n78\\n<표 3> 문항 유형별 예시-형식\\n유형 예시\\n1 빈칸채우기\\n빈칸에 들어갈 말로 올바른 것을 고르시오.\\n \\n한국 국내 증시가 저평가되는 현상을 개선하고 주\\n주가치를 높이는 것을 목표로 한국 정부는 2024\\n년 (        ) 프로그램을 추진하였다.\\n1. K-주식 활성화   2. 기업 밸류업-정답'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='1. K-주식 활성화   2. 기업 밸류업-정답   \\n3. 버블             4. 자이언트스탭\\n2 밑줄\\n다음은 영호, 민수, 진규가 하굣길에 나눈 대화의 \\n일부이다. ‘우리’ 가운데 의미하는 바가 다른 하나\\n를 고르시오.\\n영호 :  오늘 ㄱ.‘우리’ 집에서 놀 수 있어? ㄴ.‘우\\n리’ 엄마가 맛있는 케이크를 사두셨대.\\n민수 :  그래? 나 학원 가기 전까지 시간이 있으니 \\n같이 가자. 진규야 ㄷ.‘우리’ 같이 가자.\\n진규 :  좋아. 그럼 영호가 매일 ㄹ.‘우리’ 동생, 우\\n리 동생하면서 귀여워하는 수진이도 볼 수'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='리 동생하면서 귀여워하는 수진이도 볼 수 \\n있겠다.\\n1. ㄱ   2. ㄴ   3. ㄷ-정답   4. ㄹ\\n3 사실확인\\n검찰과 경찰의 수사권 차이에 대한 설명으로 옳지 \\n않은 것을 고르시오.\\n1.  고소, 고발을 통해 수사를 시작하면 경찰은 송\\n치 혹은 불송치 결정을 내리며, 검찰은 송치된 \\n사건에 대해 기소 혹은 불기소 결정을 내린다.\\n2.  검찰은 경찰 단계의 수사에 관여할 수 있다.-정답\\n3.  경찰 수사 단계에서 영장 청구가 필요한 경우 \\n검사가 관여한다.\\n4.  경찰이 수사 결과 범죄의 혐의가 없다고 판단할'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='검사가 관여한다.\\n4.  경찰이 수사 결과 범죄의 혐의가 없다고 판단할 \\n경우 불송치 결정을 해서 1차적으로 수사 종결\\n권을 행사할 수 있다.\\n4 순서나열\\n조선의 문호 개방과 관련한 사건에 대해 순서대로 \\n나열한 것을 고르시오.\\nㄱ.  자국에 대한 미국의 외교 방식을 모방하여 일\\n본이 조선에 배를 보냈다.\\nㄴ.  처음으로 관세 조항과 거중 조정 조항을 담은 \\n조약을 체결하였다.\\nㄷ.  천주교의 공인 문제로 조약 체결이 지연되었\\n던 국가와도 조약을 체결하였다.\\nㄹ.  부산뿐만 아니라 다른 두 항구를 개방하기로 \\n약조하였다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='ㄹ.  부산뿐만 아니라 다른 두 항구를 개방하기로 \\n약조하였다.\\n1. ㄱ-ㄹ-ㄴ-ㄷ-정답\\n2. ㄱ-ㄷ-ㄹ-ㄴ \\n3. ㄹ-ㄷ-ㄱ-ㄴ          \\n4. ㄷ-ㄱ-ㄴ-ㄷ\\n5 정답매칭\\n다음 중 A,B,C와 (가),(나),(다)를 가장 자연스럽\\n게 짝지은 것을 고르시오.\\nA. 충주 B. 청주 C. 공주\\n(가)  최근 해당 지자체 유튜브가 크게 화제가 된 \\n바 있다.\\n(나) 충청남도 역사박물관이 있다.\\n(다) 10월에 세종대왕과 초정약수축제가 진행된다.\\n1. A-(나)   2. B-(나)   \\n3. C-(다)   4. A-(가)-정답'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='1. A-(나)   2. B-(나)   \\n3. C-(다)   4. A-(가)-정답\\n<표 1> 벤치마크 평가 영역\\n평가 영역 세부 영역\\n1 언어 및 문\\n학\\n비문학(설명문, 논설문, 생활문, 보고서 등), \\n화법(구어 의사 소통 상황, 방언 등), 문법, 문학\\n(시, 소설, 산문, 극 등), 기타\\n2 역사\\n선사시대, 고조선과 여러 나라, 삼국시대, 남북\\n국시대, 고려시대, 조선시대, 일제시대, 현대사, \\n한국의 역사 인물, 한국의 문화유산, 한국사 통합, \\n기타\\n3 문화 및 \\n민속\\n전통 가치, 전통 의식주, 의례, 명절, 종교, 대중'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='기타\\n3 문화 및 \\n민속\\n전통 가치, 전통 의식주, 의례, 명절, 종교, 대중\\n문화, 여가문화, 무형유산, 기념일, 기타\\n4 법\\n헌법, 재산 관계와 법, 가족관계와 법, 사회생활\\n과 법, 범죄와 형벌, 국가 및 기관과 법, 생활법률, \\n기타\\n5 경제 및 \\n금융 일상생활, 경제활동, 경제정책, 금융지식, 기타\\n6 정치 한국의 민주 정치, 입법부, 사법부, 행정부, 선거와 \\n지방자치, 시민운동, 기타\\n7 지리 기후, 지형, 인구, 교통, 수도권(서울, 경기)과 지방\\n(충청도, 전라도, 경상도, 강원도, 제주도), 기타'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='(충청도, 전라도, 경상도, 강원도, 제주도), 기타\\n8 사회 한국의 상징, 가족, 일터, 교통과 통신, 주거, \\n도시와 농촌, 복지, 의료와 안전, 기타\\n9 교육 영유아교육, 초등학교, 중학교, 고등학교, \\n대학교, 대학원, 평생교육, 대안교육, 기타\\n<표 2> 문항의 형식에 따른 예시\\n문제-보기 유형 문제-지문-보기 유형\\n문제\\n다음 중 국회의원에 대한 설명\\n으로 옳지 않은 것을 모두 고르\\n시오.\\n빈칸에 들어갈 말을 알맞게 \\n짝지은 것을 고르시오.\\n지문\\n초등학교 6년과 중학교 ( )년은 \\n(        ) 기간으로 무상 교육'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='지문\\n초등학교 6년과 중학교 ( )년은 \\n(        ) 기간으로 무상 교육\\n이 제공된다.\\n보기\\n1.  2007년 12월 28일 개정하\\n여 대법관의 수를 대법원장 \\n외 13인으로 변경하였다.\\n2.  1987년 12월 4일 개정하여 \\n대법관이라는 명칭을 다시 \\n사용하였고 대법관의 수를 \\n대법원장 외 13인으로 변경\\n하였다.\\n3.  2005년 12월 15일 개정하\\n여 대법관의 수를 대법원장 \\n외 12인으로 변경하였다.\\n4.  1981년 1월 29일 개정하여 \\n대법원 판사의 수를 대법원\\n장 외 12인으로 변경하였다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='대법원 판사의 수를 대법원\\n장 외 12인으로 변경하였다.\\n1. 3, 의무 교육\\n2. 6, 의무 교육\\n3. 3, 유상 교육\\n4. 3, 비의무 교육\\n    부 록'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17'}, page_content='THE JOURNAL OF KOREAN ASSOCIATION OF COMPUTER EDUCATION Volume 27,  Issue 9,  2024\\n거대 언어 모델의 한국 이해도 평가를 위한 벤치마크 연구\\n79\\n유형 예시\\n6 복합\\n다음에서 빈칸에 들어갈 말로 알맞은 것과 해당 \\n중학교에 대한 설명을 옳게 짝지은 것을 고르시오.\\n중학교는 일반 중학교, (      ) 중학교로 구분된다.\\n1. 국립, 별도의 과정을 거쳐 선발한다.\\n2. 특성화, 집에서 가까운 곳에 배정한다.\\n3. 사립, 진로 탐색 교육을 실시한다.'), Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250711163401', 'source': '.\\\\거대 언어 모델의 한국 이해도.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17'}, page_content='2. 특성화, 집에서 가까운 곳에 배정한다.\\n3. 사립, 진로 탐색 교육을 실시한다.\\n4.  특성화, 특정 분야의 재능 있는 학생을 교육한\\n다.-정답'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='1. 서 론\\n대규모 언어모델((Large Language Model, 이하\\nLLM)은 지난 5년 동안 꾸준한 성장을 보였지만,\\nOpenAI사에서 개발한 ChatGPT 서비스의 등장 이후\\n세계적으로 LLM의 활용 방안에 관한 다양한 시도가\\n이어지고 있다. LLM은 자연어를 이해하고 또한\\n생성할 수 있도록 만들어진 대규모 딥러닝 모델이며,\\n이를 개발하기 위해서 대규모 학습데이터와 모델링\\n작업이 수행되어야 한다. 따라서 데이터와 자본의\\n한계로 해외 유명 IT 기업을 중심으로 발전하고 있어\\n국내 IT 기업의 노력에도 충분한 한국어 능력을'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='국내 IT 기업의 노력에도 충분한 한국어 능력을\\n기반한 서비스 제공에 한계가 있을 수 있다는 걱정도\\n존재한다.\\n이에 본 연구에서는 한국어를 학습한 LLM 모델\\n들을 중심으로 한국어 이해 능력을 평가하기 위해\\nKBS 한국어 능력 시험・TOPIK 등 한국어와 관련된\\n시험 문제를 중심으로 데이터셋을 구성하고 LLM의\\n성능 평가를 진행하였다. 이는 LLM의 한국어 이해\\n및 활용 능력을 객관적으로 평가하고 서비스 제공을\\n위한 가장 적절한 LLM의 선정 시 기본적인 정보를\\n제공할 수 있다.\\n2. 관련 연구\\n2.1 LLM 개념'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='제공할 수 있다.\\n2. 관련 연구\\n2.1 LLM 개념\\nLLM은 대규모의 언어모델을 의미하며, 거대한\\n데이터셋을 사용하여 훈련된 언어모델을 의미한다.\\n사전에 대규모의 언어 데이터를 학습하여 문장 구조,\\n문법, 의미, 단어 내에 내재된 다른 의미를 이해하고\\n이를 활용해 사람이 말하는 것과 유사하게 자연어를\\n생성할 수 있다. 최근 국내 주요 기업들도 초거대\\n인공지능 시스템 구축에 주력하고 있으며 이러한\\nLLM의 필요성은 더욱 커지고 있다[1][2].\\n2.2 트랜스포머(Transformer) 모델'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='2.2 트랜스포머(Transformer) 모델\\n2017년 트랜스포머 아키텍처의 등장과 함께 거대\\n대규모 언어모델의\\n한국어 이해 능력 평가 방법에 관한 연구\\n손기준1, 김승현2\\n1오피니언라이브 AI데이터센터장\\n2한국지능정보사회진흥원 책임연구원\\nkijunson@opinionlive.co.kr, shkim@nia.or.kr\\nA Study on the Evaluation Method of Korean\\nComprehension Abilities of Large Language Model\\nKi Jun Son1, Seung Hyun Kim2'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Ki Jun Son1, Seung Hyun Kim2\\n1Dept. of AI Data, Opinionlive\\n2Dept. of AI Data, National Information society Agency\\n요 약\\n최근 GTP4, LLama와 같은 초거대 언어모델을 활용한 서비스가 공개되어 많은 사람의 주목을 받고\\n있다. 해당모델들은사용자들의다양한질문에대하여유창한결과를생성하고있지만한국어데이터에\\n대한 학습량이 부족하여 한국어 이해 및 한국 문화 등에 대한 잘못된 정보를 제공하는 문제를'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='야기할수있다. 이에본논문에서는한국어데이터를학습한주요공개모델6개를선정하고5개분야\\n(한국어 이해 및 문화 영역으로 구성)에 대한 평가 데이터셋을 구성하여 한국어 이해 능력에 대한\\n평가를 진행하였다. 그 결과 한국어 구사 능력은 Bookworm 모델이, 한국어 이해 및 문화와 관련한\\n부문은 LDCC-SOLAR 모델이 우수한 것으로 확인할 수 있었다.\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x003\\x00 \\x00-'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='언어모델이등장하기시작하였으며트랜스포머모델의\\n아키텍처는 RNN, CNN을 사용하지 않고 Positional\\nEncoding을 사용하며 다수의 인코더(Encoder)와\\n디코더(Decoder)와 Attention 메커니즘을 사용한다.\\nPostional Encoding을사용하며Attention 과정을여러\\n레이어에서 반복수행하면서문장 내문맥 간의상호\\n작용에 대한 정교한 모델링이 가능하게 되었다. 이를\\n통해 번역이나 요약과 같은 작업에서 Attention과\\nNomalization 작업을 통해 성능향상을 가져왔으며'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='Nomalization 작업을 통해 성능향상을 가져왔으며\\n가장 중요한 정보를강조하여 분석할 수 있게 되었\\n다[3].\\nGoogle은 2018년 BERT (Bidirectional Encoder\\nRepresentation from Transformers)를 공개하였다.\\nBERT는 트랜스포머 모델의 인코더 아키텍처를\\n기반으로 양방향 해석을 통해 텍스트를표현하는\\n학습모델이다[4]. LLM은 대부분 트랜스포머 아키텍처\\n에서 파생된 AI 모델로, 사람의 언어, 코드 등을\\n이해하고 생성할 수 있게 되었다.\\n3. LLM 모델 평가'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='이해하고 생성할 수 있게 되었다.\\n3. LLM 모델 평가\\n3.1 평가 모델 및 항목 선정\\n최신 기술의 발전과 더불어 다양한 LLM이 공개\\n및 개방되고 있으며 이에 사용자가 모델들의 성능을\\n객관적이고세부적으로 판단할수있도록다양한평가\\n방안이 제시되고 있다. 가장 대중적으로 알려진\\nHugging Face Open LLM Leaderboard는<표1>과\\n같이 총 6가지 분야에 대한 성능을 평가하여순위를\\n정하고 있다.\\n<표1>HuggingFace Open LLM Leaderboard 평가항목\\n항목 내용\\n1 ARC 초등수준의 과학문제'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='항목 내용\\n1 ARC 초등수준의 과학문제\\n2 HellaSwag 특정 상황에서의 언어 추론 능력 평가\\n3 MMLU 사전학습 된 모델의 지식을 평가\\n4 TruthfulQA 환각현상 방지 능력\\n5 Winogrande 상식적 추론을 평가\\n6 GSM8k 다단계 수학적 추론 평가\\n또한 한국어 모델을 위하여 NIA-업스테이지에서\\n운영하는OpenKo-LLM 리더보드가운영되고있으며\\n역사왜곡,환각오류,형태소오류,불규칙활용오류,\\n혐오 표현 등을 고려한 상식생성 기준을바탕으로\\n한국어사용자가가지고있는 일반상식에부합하는지를'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='한국어사용자가가지고있는 일반상식에부합하는지를\\n기준으로 모델의 성능을 평가하고 있다.\\n먼저 평가 모델을 선정하기 위하여 2024년 2월을\\n기준으로 HuggingFace Leaderboard의 상위 100위\\n모델이며 Open Ko-LLM리더보드의 상위30위에\\n중복으로 포함된 모델을 우선 선정하였다. 그 후\\n공공부문에서활용성을고려하여한국어가학습된공개\\n모델이며, 평가에 활용할 수 있는 인프라의 성능을\\n고려하여 모델 사이즈가 12.8B 이하인 모델을 기준\\n으로 검토하여 최종적으로 <표2>에서 제시한 6개의\\n평가 모델을 선정하였다.'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='으로 검토하여 최종적으로 <표2>에서 제시한 6개의\\n평가 모델을 선정하였다.\\n<표2>평가에활용할LLM모델\\n모델명\\n1 LDCC-SOLAR-10.7B[6]\\n2 Bookworm-10.7B[7]\\n3 SOLARC-M-10.7B[8]\\n4 Llama-2-13b-chat-hf[9]\\n5 Kullm-solar[10]\\n6 KoAlpaca-Polyglot-12.8B[11]\\n*모든모델은2024년 3월20일자모델을다 운로드함\\nSOLAR모델은AI스 타트업인업스테이지에서자체\\n개발한LLM모델이며Hugging FaceLeaderboard에서'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='개발한LLM모델이며Hugging FaceLeaderboard에서\\n1위에오른적이있는모델이다. LDCC-SOLAR모델의\\n경우롯데정보통신에서SOLAR모델을 바탕으로자체\\n구축데이터를 추가 학습하여 만들어진 모델이며,\\nSOLARC-M모델의 경우SOLAR-Instruction 모델에\\nMerge기술을이용하여모델을최적화한모델이다.\\nKullm-solar 모델은 SOLAR-Instruction 모델에\\n고려대학교에서 만든 구름 데이터셋을 학습한 모델로\\nOpenKo-LLM 리더보드에서15위에기록된적이있다.'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='OpenKo-LLM 리더보드에서15위에기록된적이있다.\\nBookworm은야놀자에서업스테이지의SOLAR모델을\\n베이스로 자체 제작한 데이터셋을 학습한 후 미세\\n조정한모델이다.\\n3.2 평가 데이터셋 구성 및 방법\\n앞서설명한Hugging FaceOpenLLMLeaderboard\\n에서 선정한 6가지 분야의 성능 지표를 바탕으로\\n공공부문과 민간부문의 한국어 사용성을 고려하여\\n한국어 능력, 한국사, 한국지리, 문학, 문법 등을\\n폭넓게 평가할 수 있는 문제로총 5가지 분야 431개\\n문항을 만들어 평가를 진행하였다.\\n<표3>최종선정된평가분야'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='문항을 만들어 평가를 진행하였다.\\n<표3>최종선정된평가분야\\n데이터명(문항) 내용\\n1 KBS 한국어 능력시험(88) 한국어 문장 구조 평가\\n2 TOPIK(203) 외국인 대상 한국어 평가\\n3 한국사 능력 검정시험(40) 한국의 역사 문화 평가\\n4 국내여행안내사(50) 한국 지리적 특성 평가\\n5 공무원 9급시험(50) 문학, 문법 등 한국어 평가\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x004\\x00 \\x00-'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='<표4>LLM 성능 평가 데이터셋 구성예시\\n데이터셋 Question Answer 유형 분류\\nKBS 한국어 능력 시험\\nQ : 〈보 기〉에 제시된 단어의 발음이 표준 발음인 것끼리 묶인 것은?\\nE : <보 기> ㄱ)의심[의심]  ㄴ)본의[본이] ㄷ)닁큼[닝큼] ㄹ)무늬[무늬]\\nO : 1. ㄱ,ㄴ 2.ㄱ,ㄷ 3. ㄴ,ㄷ 4. ㄴ,ㄹ 5. ㄷ,ㄹ\\n2 (단일)정답형 어법\\nTOPIK\\nQ : ( )에 들어갈 말로 가장알맞은 것을 고르십시오.\\n    다른 사람과 대화를 할 때는 적당한 거리를(  ) 한다.'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='다른 사람과 대화를 할 때는 적당한 거리를(  ) 한다. \\nO : 1. 유지해야 2. 유지하는 3. 유지했고 4. 유지하니까\\n1 불완전\\n문장형 읽기\\n한국사 능력 검정시험\\nQ : (가)에 해당하는 인물로 옳은 것은?\\nE : 이곳 경복궁은 조선의 궁궐로 (가)이/가 이름 지었대. 국왕과 백성이 만년토\\n록 태평하며 큰 복을 누리기를 바란다는 의미가 담겨 있어. 그는 새 왕조의 통\\n치 방향을 제시한 조선경국전도 저술하였지.\\nO : 1.송시열 2.채제공 3.정몽주 4.정도전\\n4 (단일)정답형 기본\\n국내여행안내서'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='O : 1.송시열 2.채제공 3.정몽주 4.정도전\\n4 (단일)정답형 기본\\n국내여행안내서\\nQ : 소재지와 동굴의 연결이 옳은 것은?\\nO : 1. 경북 안동 - 성류굴\\n    2. 강원 삼척 - 고씨굴\\n    3. 전북 익산 - 천호동굴\\n    4. 충북 단양 - 초당굴\\n3 짝짓기형 관광자원\\n해설\\n공무원 9급시험\\nQ: 관용표현 ㄱ∼ㄹ의 의미를 풀이한 것으로 적절하지 않은 것은?\\n  - 그의 회사는 작년에 노사 갈등으로 ㄱ홍역을 치렀다. \\n  - 우리 교장 선생님은 교육계에서 ㄴ잔뼈가 굵은 분이 십니다.'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='- 우리 교장 선생님은 교육계에서 ㄴ잔뼈가 굵은 분이 십니다.\\n  - 유원지로 이어지는 국도에는 차가 밀려 ㄷ입추의 여지가 없었다.\\n  - 그분은 세계 유수의 연구자들과 ㄹ어깨를 나란히 하는 물리학자이다.\\nO : 1. ㄱ: 심한 어려움을 겪었다 2. ㄴ:오랫동안 일을 하여 그 일에 익숙한 \\n    3. ㄷ: 돌아서 갈 수 있는 방법이 없었다 4. ㄹ:비슷한 지위나 힘을 가지는\\n3\\n불완전 \\n문장형 어휘\\n<표5>LLM 평가 결과\\n모델명\\nKBS 한국어 능력시험 TOPIK 한국사능력검정시험 국내여행안내사 공무원 9급 시험'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='KBS 한국어 능력시험 TOPIK 한국사능력검정시험 국내여행안내사 공무원 9급 시험\\n정답수 비율(%) 정답수 비율(%) 정답수 비율(%) 정답수 비율(%) 정답수 비율(%)\\nLDCC-SOLAR-10.7B 20 23 146 72 18 45 23 46 28 55\\nBookworm-10.7B 21 24 152 75 10 25 21 42 26 51\\nSOLARC-M-10.7B 15 17 141 70 14 35 20 4 23 45\\nLlama-2-13b-chat-hf 18 20 83 41 0 0 9 18 11 22'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='Llama-2-13b-chat-hf 18 20 83 41 0 0 9 18 11 22\\nKullm-solar 8 9 87 43 2 5 6 12 10 20\\nKoAlpaca-Polyglot-12.8B 13 15 33 16 8 2 12 24 6 12\\n3.3 평가 결과\\n선정된 LLM의 한국어 이해에 대한 평가를 진행\\n하기 위하여 평가에 활용할 데이터셋<표4>을 객관식\\n문제 유형으로 구성하였다. 평가는 모델별 입력구조가\\n다양하여 입력 형식에 맞추어 프롬프트를 구성한 후\\n테스트를 진행하였다.\\n한국어 능력을 평가하기 위해서 시행한‘KBS'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='테스트를 진행하였다.\\n한국어 능력을 평가하기 위해서 시행한‘KBS\\n한국어 능력 시험’과‘TOPIK’ 시험의 결과는<표5>와\\n같다.‘KBS 한국어 능력 시험’의경우 문법과 어휘를\\n중심으로 한국어 문장의 구조를 이해하는 능력을\\n평가하게 되며,‘TOPIK’의 경우 한국어를 모국어로\\n사용하지 않는 이를 대상으로 수행되는 시험으로\\n언어의 사용 및 이해도에 대한 평가로 Bookworm\\n모델이 가장높은 정답률을 보였다.\\n‘한국사능력검정시험’과 ‘국내 여행 안내사 시험’의\\n경우는 한국의 역사와 문화 지식 측정이 목표인 시험'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='경우는 한국의 역사와 문화 지식 측정이 목표인 시험\\n으로LDCC-SOLAR모델이가장 좋은성능을보였다.\\n‘공무원 9급 시험’의 경우 한국 문학, 문법, 한자\\n표현 등을 포함한 한국어 능력을폭넓게 평가하여\\n문장의 맥락을 정확히이해하고 사용할 수 있는지\\n평가하게 된다.‘국내 여행 안내사 시험’과‘공무원9급\\n시험’의 경우 LDCC_SOLAR 모델의 정답률이 가장\\n높게 나왔으며 Boookworm 모델이 근소한차이로\\n두번째로좋은정답률을보이는것을확인할수있다.\\n모델별 평가 결과는<표6>에서 확인할 수 있다.'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='두번째로좋은정답률을보이는것을확인할수있다.\\n모델별 평가 결과는<표6>에서 확인할 수 있다.\\n롯데정보통신의 LDCC-SOLAR가 가장좋은 결과를\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x005\\x00 \\x00-'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='나타냈으며, 야놀자의 Bookworm이 2순위를 기록하였\\n으며 SOLARC-M 모델도 정답률이 49%로 준수한\\n결과를 보여주었다. 다만 나머지3개 모델은 정답률이\\n30%에 미치지 못하여 상대적으로낮은 수준을 나타\\n냈음을확인할수있다.\\n<표6>LLM 평가 결과종합\\n순위 모델명 정답수 비율(%)\\n1 LDCC-SOLAR-10.7B 235 55\\n2 Bookworm-10.7B 230 53\\n3 SOLARC-M-10.7B 213 49\\n4 Llama-2-13b-chat-hf 121 28\\n5 Kullm-solar 113 26'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='4 Llama-2-13b-chat-hf 121 28\\n5 Kullm-solar 113 26\\n6 KoAlpaca-Polyglot-12.8B 72 17\\n상위권을기록한모델들의공통 점은베이스모델을\\n모두업스테이지가개발한SOLAR를기본으로만들어\\n졌음을 확인할 수 있다. SOLAR 모델의경우 LLM의\\n효율적인확장을위한 깊이기반스 케일링과지속적인\\n사전 훈련을 통해 모델을 구축하였으며,롯데정보\\n통신과 야놀자에서는 자체 구축데이터를 통해서\\n한국어와 관련한 다양한 분야의추가 학습이 지속해서\\n진행되어 높은 정답률을 보일수 있던 것으로 판단'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='진행되어 높은 정답률을 보일수 있던 것으로 판단\\n된다. 따라서우수한데이터를지속해서학습하는것이\\nLLM의 성능을높일 수 있는 가장좋은 방법임을\\n확인할 수 있다.\\n4. 결 론\\n공공분야 및 민간분야에서의 LLM을 활용하여\\n다양한 서비스 제공을 위해 노력하고 있다. 이를 위\\n해선 서비스의 목적에맞는 모델을 선정하고 해당\\n모델의 장단점을 정확히 이해하는 것에서 시작된다고\\n할 수 있다. 이를 위해 본 연구는 한국어와 관련한\\n다양한 문제풀이 방식을 통해 6개의 LLM에 대한\\n성능을 평가 및 분석하였다. 세부적으로 한국어 구사'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='성능을 평가 및 분석하였다. 세부적으로 한국어 구사\\n능력은야놀자의Bookworm모델이가장우수한것으로\\n나타났으며, 한국사, 한국 지리그리고 공무원 9급\\n시험 문제에서는 롯데정보통신의 LDCC-SOLAR\\n모델이 우수한 것으로 평가되었다.향후 LLM 기술은\\n산업별 응용에서 중요한 역할을차지할 것이며, 이를\\n위한 올바른 평가는 중요한 역할을 할 것으로 생각\\n된다. 이에 초거대 언어모델의 한국어 이해 능력을\\n평가하기 위한 다양한 데이터셋 구축 및 평가 지표에\\n대한 개발이 필요할 것으로 생각된다.\\n참고문헌'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='대한 개발이 필요할 것으로 생각된다.\\n참고문헌\\n[1] S. Lim and S. Lee “Research Trends in\\nArtificial Intelligence Language Models ”,\\nInformation and Communication Magazine, Vol 40,\\nNo.3, pp.42-50, 2023.\\n[2] M. Shanahan“Talking about large language\\nmodels”, Communication of the ACM,Vol 67, No.\\n2, pp68-79, 2024.'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='2, pp68-79, 2024.\\n[3] A. Vaswani, N. Shazeer, N. Parmar, J.\\nUszkoreit, L. Jones, A.N. Gomez et al.,“Attention\\nis AllYou Need”, Advances in Neural Information\\nProcessing Systems, pp5998-6008, 2017.\\n[4] J. Devlin, M. Chang, K. Lee, and K. Toutanova,'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='“BERT:Pre-training of Deep Bidirectional Transformers\\nfor Language Understanding”, North America\\nChaper of the Association for Computational\\nLiguistics, pp4171-4186, 2018.\\n[5] A, Radfordm J, Narasimhan, T. Salimans, and\\nI. Sutskever, Improving LanguageUnderstanding'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='I. Sutskever, Improving LanguageUnderstanding\\nby Generarive Pre-training, OpenAI, 2018\\n[6] LDCC. (2024, February 28). LDCC/LDCC\\n-SOLAR-10.7B. Hugging Face. https://hugging\\nface.co/LDCC/LDCC-SOLAR-10.7B\\n[7] Yanolja. (2024, March 16).Yanolja/Bookworm-\\n10.7B-v0.4-DPO. Hugging Face. https://hugging'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='10.7B-v0.4-DPO. Hugging Face. https://hugging\\nface.co/yanolja/Bookworm-10.7B-v0.4-DPO\\n[8] Dopeornope. (2024, January 15). DopeorNope\\n/SOLARC-M-10.7B. HuggingFace. https://hugging\\nface.co/DopeorNope/SOLARC-M-10.7B\\n[9] Meta. (2023, November 13). Meta-Llama/Llama'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='[9] Meta. (2023, November 13). Meta-Llama/Llama\\n-2-13b-Hf. Hugging Face. https://huggingface.co/\\nmeta-llama/Llama-2-13b-hf\\n[10] Heavytail. (2024, January 2 8). Heavytail/\\nKullm-Solar. HuggingFace. https://huggingface.co/\\nheavytail/kullm-solar\\n[11] Beomi.(2023,May 3).Beomi/KoAlpaca-Polyglot-12.8B.'), Document(metadata={'producer': 'Adobe Acrobat Pro 10.1.1', 'creator': 'Adobe Acrobat Pro 10.1.1', 'creationdate': '2024-05-16T14:16:03+09:00', 'author': '류성호', 'moddate': '2024-05-16T14:16:03+09:00', 'source': '.\\\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='Hugging Face.\\n https://huggingface.co/beomi/\\nKoAlpaca-Polyglot -12.8B\\nASK 2024 학술발표대회 논문집 (31권 1호)\\n\\x00-\\x00 \\x007\\x003\\x006\\x00 \\x00-')]\n"
     ]
    }
   ],
   "source": [
    "# Splitter를 이용한 청킹\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 50\n",
    "    )\n",
    "\n",
    "#splitter를 이용한 문서 청킹\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e71a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjsd4\\AppData\\Local\\Temp\\ipykernel_26408\\4234635357.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#임베딩 모델 생성\n",
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\", \n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a1ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n"
     ]
    }
   ],
   "source": [
    "#크로마 벡터 영구 저장소 지정\n",
    "persist_directory = r'.\\chroma'\n",
    "\n",
    "#벡터 저장소\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619ba8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "진행되어 높은 정답률을 보일수 있던 것으로 판단\n",
      "된다. 따라서우수한데이터를지속해서학습하는것이\n",
      "LLM의 성능을높일 수 있는 가장좋은 방법임을\n",
      "확인할 수 있다.\n",
      "4. 결 론\n",
      "공공분야 및 민간분야에서의 LLM을 활용하여\n",
      "다양한 서비스 제공을 위해 노력하고 있다. 이를 위\n",
      "해선 서비스의 목적에맞는 모델을 선정하고 해당\n",
      "모델의 장단점을 정확히 이해하는 것에서 시작된다고\n",
      "할 수 있다. 이를 위해 본 연구는 한국어와 관련한\n",
      "다양한 문제풀이 방식을 통해 6개의 LLM에 대한\n",
      "성능을 평가 및 분석하였다. 세부적으로 한국어 구사\n"
     ]
    }
   ],
   "source": [
    "question = \"한국형 LLM?\"\n",
    "\n",
    "docs = vectordb.similarity_search(question, k=3)  #return 받고자하는 문서의 수를 3개로 지정\n",
    "\n",
    "# 문서 길이 확인\n",
    "print(len(docs))\n",
    "\n",
    "# 첫번째 문서의 콘텐츠 확인\n",
    "print(docs[0].page_content)\n",
    "\n",
    "# 영구 저장\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8df0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국내 IT 기업의 노력에도 충분한 한국어 능력을\n",
      "기반한 서비스 제공에 한계가 있을 수 있다는 걱정도\n",
      "존재한다.\n",
      "이에 본 연구에서는 한국어를 학습한 LLM 모델\n",
      "들을 중심으로 한국어 이해 능력을 평가하기 위해\n",
      "KBS 한국어 능력 시험・TOPIK 등 한국어와 관련된\n",
      "시험 문제를 중심으로 데이터셋을 구성하고 LLM의\n",
      "성능 평가를 진행하였다. 이는 LLM의 한국어 이해\n",
      "및 활용 능력을 객관적으로 평가하고 서비스 제공을\n",
      "위한 가장 적절한 LLM의 선정 시 기본적인 정보를\n",
      "제공할 수 있다.\n",
      "2. 관련 연구\n",
      "2.1 LLM 개념\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8efc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공할 수 있다.\n",
      "2. 관련 연구\n",
      "2.1 LLM 개념\n",
      "LLM은 대규모의 언어모델을 의미하며, 거대한\n",
      "데이터셋을 사용하여 훈련된 언어모델을 의미한다.\n",
      "사전에 대규모의 언어 데이터를 학습하여 문장 구조,\n",
      "문법, 의미, 단어 내에 내재된 다른 의미를 이해하고\n",
      "이를 활용해 사람이 말하는 것과 유사하게 자연어를\n",
      "생성할 수 있다. 최근 국내 주요 기업들도 초거대\n",
      "인공지능 시스템 구축에 주력하고 있으며 이러한\n",
      "LLM의 필요성은 더욱 커지고 있다[1][2].\n",
      "2.2 트랜스포머(Transformer) 모델\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091e14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
