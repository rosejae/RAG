{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af96807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033f0882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "Advanced encoding /UniKS-UTF16-H not implemented yet\n",
      "C:\\Users\\jjsd4\\AppData\\Local\\Temp\\ipykernel_14216\\4224864129.py:9: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    }
   ],
   "source": [
    "# load pdf\n",
    "pdf_filepath = r'.\\대규모 언어모델의 한국어 이해 능력 평가 방법에 관한 연구.pdf'\n",
    "loader = PyPDFLoader(pdf_filepath)\n",
    "data  = loader.load()\n",
    "\n",
    "# split data and embedding\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "data = text_splitter.split_documents(data)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# vector DB\n",
    "vectorstore = FAISS.from_documents(data, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b9103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjsd4\\AppData\\Local\\Temp\\ipykernel_14216\\336438762.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
      "C:\\Users\\jjsd4\\AppData\\Local\\Temp\\ipykernel_14216\\336438762.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02dfe5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjsd4\\AppData\\Local\\Temp\\ipykernel_14216\\2801801730.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = conversation_chain({\"question\": query})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'대규모 언어모델의 한국어 이해 능력은 한국어를 이해하고 생성하는 능력을 말합니다. 이러한 언어모델은 대규모의 학습 데이터와 딥러닝 기술을 활용하여 문장 구조, 어휘, 문법, 의미 등을 이해하고 이를 활용하여 자연스러운 한국어 문장을 생성할 수 있습니다. 이를 통해 해당 언어모델은 한국어 텍스트를 이해하고 다양한 작업에 활용할 수 있는 능력을 갖게 됩니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"대규모 언어모델의 한국어 이해 능력이란?\"\n",
    "result = conversation_chain({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12105583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'본 연구에서는 한국어를 학습한 LLM 모델들을 중심으로 한국어 이해 능력을 평가하였습니다. 예를 들어, KBS 한국어 능력 시험, TOPIK 시험, 한국사 능력 검정시험, 국내 여행 안내사 시험, 그리고 공무원 9급 시험과 같은 한국어와 관련된 시험 문제를 사용하여 LLM의 성능을 평가하였습니다. 이를 통해 LLM 모델들의 한국어 이해 능력을 객관적으로 평가하고 서비스 제공을 위한 적합한 모델을 선정하는 데 도움이 되었습니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"그럼 그에 대한 몇가지 예를 보여줘\"\n",
    "result = conversation_chain({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc324a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
